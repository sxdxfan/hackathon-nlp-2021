{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "from glob import glob\n",
    "import re\n",
    "import os\n",
    "import os.path\n",
    "from string import punctuation\n",
    "import pickle\n",
    "from modAL.models import ActiveLearner\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, GridSearchCV, KFold\n",
    "from nltk.corpus import stopwords\n",
    "from ftfy import fix_text\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, roc_auc_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.callbacks import DeadlineStopper, VerboseCallback, DeltaXStopper, DeltaYStopper\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import catboost\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_highlighted_text(paragraph):\n",
    "    for run in paragraph.runs:\n",
    "        if run.font.highlight_color:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_text(filename):\n",
    "    doc = docx.Document(filename)\n",
    "    full_text, corrupt_text = [], []\n",
    "    for paragraph in doc.paragraphs:\n",
    "        full_text.append(paragraph.text)\n",
    "        if check_highlighted_text(paragraph):\n",
    "            corrupt_text.append(paragraph.text)\n",
    "    return \"\\n\".join(full_text), \"\\n\".join(corrupt_text)\n",
    "\n",
    "def get_paragraph_with_labels(filename):\n",
    "    doc = docx.Document(filename)\n",
    "    paragraphs_with_labels = []\n",
    "    highlight_text_flg = False\n",
    "    for paragraph in doc.paragraphs:\n",
    "        if paragraph.text:\n",
    "            if check_highlighted_text(paragraph):\n",
    "                paragraphs_with_labels.append((paragraph.text, 1, filename))\n",
    "                highlight_text_flg = True\n",
    "            else:\n",
    "                paragraphs_with_labels.append((paragraph.text, 0, filename))\n",
    "    return paragraphs_with_labels, highlight_text_flg\n",
    "\n",
    "def get_label(filename):\n",
    "    label = filename.split('/')[6]\n",
    "    return label\n",
    "\n",
    "def get_factor_description(filename):\n",
    "    doc = docx.Document(filename)\n",
    "    full_text = []\n",
    "    for paragraph in doc.paragraphs:\n",
    "        full_text.append(paragraph.text)\n",
    "        if check_highlighted_text(paragraph):\n",
    "            corrupt_text.append(paragraph.text)\n",
    "    return \"\\n\".join(full_text), \"\\n\".join(corrupt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = dict()\n",
    "\n",
    "for file_path in tqdm(glob(\"/home/hackathon/dataset/dataset_razmetka/**/*.docx\", recursive=True)):\n",
    "    if \"~$\" in file_path:\n",
    "        continue\n",
    "    label = file_path.strip('/').split('/')[5]\n",
    "    \n",
    "    if file_path not in texts:\n",
    "        texts[file_path] = {'expertise_text': np.nan, \n",
    "                            'full_nc_text': np.nan, \n",
    "                            'corrupt_nc_text': np.nan,\n",
    "                            'full_text': np.nan,\n",
    "                            'corrupt_text': np.nan,\n",
    "                            'label': label\n",
    "                           }\n",
    "        \n",
    "    if 'Expertise_Text' in file_path:\n",
    "        try:\n",
    "            full_expertise_text, _ = get_text(file_path)\n",
    "            texts[file_path]['expertise_text'] = full_expertise_text\n",
    "        except:\n",
    "            continue\n",
    "    if '/NC_Edition_Text' in file_path:\n",
    "        try:\n",
    "            full_nc_text, corrupt_nc_text = get_text(file_path)\n",
    "            texts[file_path]['full_nc_text'] = full_nc_text\n",
    "            texts[file_path]['corrupt_nc_text'] = corrupt_nc_text\n",
    "        except:\n",
    "            continue\n",
    "    if '/Edition_Text' in file_path:\n",
    "        try:\n",
    "            full_text, corrupt_text = get_text(file_path)\n",
    "            texts[file_path]['full_text'] = full_text\n",
    "            texts[file_path]['corrupt_text'] = corrupt_text\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'texts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24549/223238984.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw_texts_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mraw_texts_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mraw_texts_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'path'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mraw_texts_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'raw_texts.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'texts' is not defined"
     ]
    }
   ],
   "source": [
    "raw_texts_df = pd.DataFrame.from_dict(texts).T\n",
    "raw_texts_df.reset_index(inplace=True)\n",
    "raw_texts_df.rename(columns={'index': 'path'}, inplace=True)\n",
    "raw_texts_df.to_csv('raw_texts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_texts_df = pd.read_csv('raw_texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_data_without_nulls(data, col):\n",
    "    grouped_data = data.groupby('path')[col].apply(set).reset_index()\n",
    "    grouped_data = grouped_data[grouped_data[col] != {np.nan}]\n",
    "    grouped_data[col] = grouped_data[col].apply(lambda x: list(x)[0])\n",
    "    return grouped_data\n",
    "\n",
    "full_nc_text = return_data_without_nulls(raw_texts_df, 'full_nc_text')\n",
    "expertise_text = return_data_without_nulls(raw_texts_df, 'expertise_text')\n",
    "corrupt_nc_text = return_data_without_nulls(raw_texts_df, 'corrupt_nc_text')\n",
    "full_text = return_data_without_nulls(raw_texts_df, 'full_text')\n",
    "corrupt_text = return_data_without_nulls(raw_texts_df, 'corrupt_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5452, 2), (5377, 2), (4158, 2), (5441, 2), (4241, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_nc_text.shape, expertise_text.shape, corrupt_nc_text.shape, full_text.shape, corrupt_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_texts = pd.merge(full_nc_text, corrupt_nc_text)\n",
    "source_texts = pd.merge(full_text, corrupt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df = pd.merge(source_texts, raw_texts_df, on='path', suffixes=('', '_y'))\n",
    "texts_df = texts_df.iloc[:, [0, 1, 2, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_freq_labels = [value for value in dict(texts_df['label'].value_counts()).values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4_1': '884',\n",
       " '3_3': '691',\n",
       " '3_7': '608',\n",
       " '3_1': '574',\n",
       " '3_9': '445',\n",
       " '3_5': '368',\n",
       " '4_2': '233',\n",
       " '4_3': '181',\n",
       " '3_2': '166',\n",
       " '3_6': '53',\n",
       " '3_4': '35',\n",
       " '3_8': '3'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(np.c_[list(dict(texts_df['label'].value_counts()).keys()), add_freq_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_to_replace = {old_label: new_label for new_label, old_label in enumerate(texts_df['label'].unique())}\n",
    "texts_df['label'] = texts_df['label'].map(map_to_replace)\n",
    "texts_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3_1': 0,\n",
       " '3_2': 1,\n",
       " '3_5': 2,\n",
       " '3_9': 3,\n",
       " '4_1': 4,\n",
       " '4_3': 5,\n",
       " '3_3': 6,\n",
       " '3_7': 7,\n",
       " '4_2': 8,\n",
       " '3_4': 9,\n",
       " '3_6': 10,\n",
       " '3_8': 11}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_to_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text):\n",
    "    file_vectorizer = open('new_vectorizer.pkl', 'rb')\n",
    "    vectorizer = pickle.load(file_vectorizer)\n",
    "    vectorized_text = vectorizer.transform(text)\n",
    "    return vectorized_text\n",
    "\n",
    "def predict_factor(vectorized_text):\n",
    "    file_logreg = open('logreg.pkl', 'rb')\n",
    "    lr = pickle.load(file_vectorizer)\n",
    "    predicted_factor = lr.predict(vectorized_text)\n",
    "    return predicted_factor\n",
    "\n",
    "vectorized_text = vectorize_text(corrupt_text)\n",
    "factor = predict_factor(vectorized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts_df['count_puncts'] = texts_df['corrupt_text'].apply(lambda x: len(re.findall(r'[.,:?;!)(]*', x)))\n",
    "# texts_df = texts_df[texts_df['count_puncts'] != texts_df['count_puncts'].max()]\n",
    "\n",
    "# texts_df['corrupt_text'] = texts_df['corrupt_text'].apply(lambda x: re.sub(r'\\s', ' ', x.strip()))\n",
    "# texts_df['first_word'] = texts_df['corrupt_text'].apply(lambda x: x.split(' ')[0].strip().lower())\n",
    "# texts_df['last_word'] = texts_df['corrupt_text'].apply(lambda x: x.split(' ')[-1].strip().lower())\n",
    "# texts_df['count_decimal'] = texts_df['corrupt_text'].apply(lambda x: len(re.findall(r'[0-9]+', x)))\n",
    "# texts_df['count_uppercased_chars'] = texts_df['corrupt_text'].apply(lambda x: len(re.findall(r'[A-ZA-Я]+', x)))\n",
    "# texts_df['len_line'] = texts_df['corrupt_text'].apply(lambda x: len(x))\n",
    "# texts_df['count_stopwords'] = texts_df['corrupt_text'].apply(lambda x: len([token for token in x.split(' ') if token in stopwords.words('russian')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     20.844141\n",
       "6     16.293327\n",
       "7     14.336241\n",
       "0     13.534544\n",
       "3     10.492808\n",
       "2      8.677199\n",
       "8      5.493987\n",
       "5      4.267861\n",
       "1      3.914171\n",
       "10     1.249705\n",
       "9      0.825277\n",
       "11     0.070738\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df['label'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#texts_df['len_line'] = texts_df['corrupt_text'].apply(lambda x: len(x))\n",
    "#texts_df = texts_df[(texts_df['len_line'].quantile(0.10) < texts_df['len_line']) & (texts_df['len_line'] < texts_df['len_line'].quantile(0.90))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     705\n",
       "6     536\n",
       "0     487\n",
       "7     437\n",
       "3     396\n",
       "2     305\n",
       "8     163\n",
       "5     162\n",
       "1     138\n",
       "9      32\n",
       "10     27\n",
       "11      3\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corrupt_texts = ' '.join([str(row) for row in texts_df['corrupt_text'].values.tolist()])\n",
    "\n",
    "vectorizer = TfidfVectorizer(corrupt_texts, ngram_range=(1, 2), stop_words=stopwords.words('russian'), min_df=0.005)\n",
    "x_train, x_test, y_train, y_test = train_test_split(texts_df['corrupt_text'].values, texts_df['label'].values, test_size=0.1, random_state=42, stratify=texts_df['label'].values)\n",
    "dop_text = x_train[y_train == 11][0]\n",
    "x_test = np.append(x_test, x_train[y_train == 11][0])\n",
    "y_test = np.append(y_test, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorizer.fit_transform(x_train)\n",
    "x_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hackathon/code/venv/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:1323: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/hackathon/code/venv/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='saga', C=1000, penalty='none')\n",
    "\n",
    "learner = ActiveLearner(\n",
    "                        estimator=lr,\n",
    "    X_training=x_train, y_training=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4812206572769953"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lr.fit(x_train, y_train)\n",
    "y_pred = learner.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.41      0.39        58\n",
      "           1       1.00      0.29      0.45        17\n",
      "           2       0.60      0.57      0.58        37\n",
      "           3       0.48      0.51      0.49        45\n",
      "           4       0.62      0.88      0.73        89\n",
      "           5       0.50      0.22      0.31        18\n",
      "           6       0.50      0.48      0.49        69\n",
      "           7       0.41      0.43      0.42        61\n",
      "           8       0.67      0.17      0.28        23\n",
      "           9       1.00      0.33      0.50         3\n",
      "          10       1.00      1.00      1.00         5\n",
      "          11       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.53       426\n",
      "   macro avg       0.60      0.44      0.47       426\n",
      "weighted avg       0.54      0.53      0.51       426\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hackathon/code/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hackathon/code/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/hackathon/code/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer, open('../models/vectorizer.pkl', 'wb'))\n",
    "pickle.dump(lr, open('../models/logreg.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_feat_imp(model, label, vectorizer):\n",
    "    feat_imp = pd.DataFrame(np.c_[list(vectorizer.vocabulary_), model.coef_[label]], columns=['word', 'coef'])\n",
    "    feat_imp['coef'] = feat_imp['coef'].astype('float64')\n",
    "    return feat_imp.sort_values(by='coef', ascending=False)\n",
    "\n",
    "def create_features_from_feat_imp(data, feature_importances):\n",
    "    best_words = feature_importances['word'].head(10).values\n",
    "    for word in best_words:\n",
    "        col_name = 'gram_' + word.replace(' ', '_') + '_flg'\n",
    "        data[col_name] = data['line'].apply(lambda x: 1 if word.lower() in x else 0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>заверенные</td>\n",
       "      <td>12.742390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>тысяч</td>\n",
       "      <td>9.669672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3626</th>\n",
       "      <td>нарушением требований</td>\n",
       "      <td>9.181961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>летнего</td>\n",
       "      <td>8.446023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>прилагаются</td>\n",
       "      <td>8.261875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>физическим</td>\n",
       "      <td>7.718153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3151</th>\n",
       "      <td>инвалидности</td>\n",
       "      <td>7.608404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2933</th>\n",
       "      <td>иного документа</td>\n",
       "      <td>7.309854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>отказывает удовлетворении</td>\n",
       "      <td>7.290484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>10 дней</td>\n",
       "      <td>7.239311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>заявителю</td>\n",
       "      <td>7.104895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>услуги основания</td>\n",
       "      <td>7.078522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>контактный</td>\n",
       "      <td>7.002424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>совместно</td>\n",
       "      <td>6.855675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>установленных</td>\n",
       "      <td>6.820433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           word       coef\n",
       "3658                 заверенные  12.742390\n",
       "2335                      тысяч   9.669672\n",
       "3626      нарушением требований   9.181961\n",
       "2705                    летнего   8.446023\n",
       "78                  прилагаются   8.261875\n",
       "975                  физическим   7.718153\n",
       "3151               инвалидности   7.608404\n",
       "2933            иного документа   7.309854\n",
       "1423  отказывает удовлетворении   7.290484\n",
       "3819                    10 дней   7.239311\n",
       "28                    заявителю   7.104895\n",
       "409            услуги основания   7.078522\n",
       "1723                 контактный   7.002424\n",
       "2558                  совместно   6.855675\n",
       "666               установленных   6.820433"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_feat_imp(lr, 2, vectorizer).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hackathon/dataset/dataset_razmetka/Волгоградская область/4_1/C3672823-62B8-4565-B451-C6F4AD43746C/Edition_4/Edition_Text.docx'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob(\"/home/hackathon/dataset/dataset_razmetka/**/*Edition_Text.docx\", recursive=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 5441/5441 [03:18<00:00, 27.47it/s]\n"
     ]
    }
   ],
   "source": [
    "edition_texts = []\n",
    "paths = glob(\"/home/hackathon/dataset/dataset_razmetka/**/Edition_Text.docx\", recursive=True)\n",
    "\n",
    "for file_path in tqdm(paths):\n",
    "    try:\n",
    "        marked_text, highlight_text_flg = get_paragraph_with_labels(file_path)\n",
    "        if highlight_text_flg:\n",
    "            edition_texts.extend(marked_text)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_texts_df = pd.DataFrame(edition_texts, columns=['line', 'label', 'file_path'])\n",
    "ed_texts_df['factor'] = ed_texts_df['file_path'].apply(lambda file_path: file_path.strip('/').split('/')[5])\n",
    "ed_texts_df.to_csv('ed_texts_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_texts_df = pd.read_csv('ed_texts_df.csv')\n",
    "ed_texts_df_0 = ed_texts_df[ed_texts_df['label'] == 0]\n",
    "ed_texts_df_0 = ed_texts_df_0.sample(int(ed_texts_df_0.shape[0] * 0.4))\n",
    "ed_texts_df_1 = ed_texts_df[ed_texts_df['label'] == 1]\n",
    "ed_texts_df = pd.concat([ed_texts_df_0, ed_texts_df_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(715136, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ed_texts_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #prepare data for gpt\n",
    "\n",
    "# corrupt_ed_texts_df = ed_texts_df[ed_texts_df['label'] == 1]\n",
    "# joined_corrupt_ed_texts_df = corrupt_ed_texts_df.groupby('file_path', as_index=False)['line'].apply(lambda x: '<br>'.join(x))\n",
    "# joined_corrupt_ed_texts_df.drop_duplicates(['line'], inplace=True)\n",
    "# joined_corrupt_ed_texts_df = pd.merge(joined_corrupt_ed_texts_df, corrupt_ed_texts_df, how='left', on='file_path')\n",
    "# joined_corrupt_ed_texts_df = joined_corrupt_ed_texts_df.iloc[:, [0, 1, 3, 4]]\n",
    "# joined_corrupt_ed_texts_df.drop_duplicates(['file_path', 'line_x'], inplace=True)\n",
    "# joined_corrupt_ed_texts_df['prepared_line'] = '[' + joined_corrupt_ed_texts_df['factor'] + '] ' + joined_corrupt_ed_texts_df['line_x'].apply(lambda x: fix_text(x))\n",
    "# joined_corrupt_ed_texts_df['prepared_line'] = joined_corrupt_ed_texts_df['prepared_line'].apply(lambda x: re.sub(r'\\s', ' ', x))\n",
    "# prepared_lines = joined_corrupt_ed_texts_df['prepared_line'].sample(joined_corrupt_ed_texts_df['file_path'].shape[0]).values\n",
    "\n",
    "# with open('../dataset/gpt_corrupt_lines_1.txt', 'w') as f:\n",
    "#     f.write('\\n'.join(prepared_lines[:1600]))\n",
    "    \n",
    "# with open('../dataset/gpt_corrupt_lines_2.txt', 'w') as f:\n",
    "#     f.write('\\n'.join(prepared_lines[1600:3200]))\n",
    "\n",
    "# with open('../dataset/gpt_corrupt_lines_3.txt', 'w') as f:\n",
    "#     f.write('\\n'.join(prepared_lines[3200:4800]))\n",
    "    \n",
    "# with open('../dataset/gpt_corrupt_lines_4.txt', 'w') as f:\n",
    "#     f.write('\\n'.join(prepared_lines[4800:6400]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data_folder = os.listdir('../dataset/generated_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data = pd.DataFrame(columns=['text', 'label'])\n",
    "\n",
    "for file_name in generated_data_folder:\n",
    "    file_path = os.path.join('/home/hackathon/dataset/generated_data', file_name)\n",
    "    new_generated_data = pd.read_csv(file_path)\n",
    "    generated_data = generated_data.append(new_generated_data)\n",
    "    \n",
    "generated_data_1 = pd.read_csv('../dataset/generated_texts.csv')\n",
    "\n",
    "generated_data = pd.concat([generated_data, generated_data_1])\n",
    "generated_data.drop_duplicates(['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[3_1] 6.2. Работнику учреждения может быть оказана материальная помощь в случаях:\\n1) вступления работника учреждения в брак;\\n2) рождения у работника учреждения ребёнка либо усыновления им ребёнка;\\n3) наличия у работника учреждения тяжёлого заболевания, требующего продолжительного и (или) дорогостоящего лечения;\\n4) смерти супруга (супруги) и (или) близких родственников работника учреждения.',\n",
       " '3_1']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_data.values[:2].tolist()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3_1', '3_6', '3_9', '3_3', '4_3', '3_7', '3_2', '4_2', '3_8',\n",
       "       '3_5', '4_1', '3_4'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_data['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_data['new_text'] = generated_data['text'].apply(lambda x: x[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_lines = []\n",
    "\n",
    "for row in generated_data.values:\n",
    "    text_lines = row[2].split('\\n')\n",
    "    lines_label = [(line, 1) for line in text_lines]\n",
    "    generated_lines.extend(lines_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_lines = pd.DataFrame(generated_lines, columns=['line', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(filename):\n",
    "    doc = docx.Document(filename)\n",
    "    full_text = []\n",
    "    for paragraph in doc.paragraphs:\n",
    "        if paragraph.text:\n",
    "            full_text.append(paragraph.text)\n",
    "    return full_text\n",
    "\n",
    "def get_label(filename):\n",
    "    label = filename.split('/')[6]\n",
    "    return label\n",
    "\n",
    "def preprocess_data(data):\n",
    "    data['line'] = data['line'].apply(lambda x: re.sub(r'\\s', ' ', str(x).strip()))\n",
    "    data['len_line'] = data['line'].apply(lambda x: len(x))\n",
    "    data['first_word'] = data['line'].apply(lambda x: x.split(' ')[0].strip().lower())\n",
    "    data['last_word'] = data['line'].apply(lambda x: x.split(' ')[-1].strip().lower())\n",
    "    data['count_decimal'] = data['line'].apply(lambda x: len(re.findall(r'[0-9]+', x)))\n",
    "    data['count_uppercased_chars'] = data['line'].apply(lambda x: len(re.findall(r'[A-ZA-Я]+', x)))\n",
    "    data['count_stopwords'] = data['line'].apply(lambda x: len([token for token in x.split(' ') if token in stopwords.words('russian')]))\n",
    "    data['count_puncts'] = data['line'].apply(lambda x: len(re.findall(r'[.,:?;!)(*%#]\\\"\\'', x)))\n",
    "    return data\n",
    "\n",
    "def return_feat_imp(model, label, vectorizer):\n",
    "    feat_imp = pd.DataFrame(np.c_[list(vectorizer.vocabulary_), model.coef_[label]], columns=['word', 'coef'])\n",
    "    feat_imp['coef'] = feat_imp['coef'].astype('float64')\n",
    "    return feat_imp.sort_values(by='coef', ascending=False)\n",
    "\n",
    "def create_features_from_feat_imp(data, feature_importances):\n",
    "    best_words = feature_importances['word'].head(10).values\n",
    "    for word in best_words:\n",
    "        col_name = 'gram_' + word.replace(' ', '_') + '_flg'\n",
    "        data[col_name] = data['line'].apply(lambda x: 1 if word.lower() in x else 0)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_texts_df = pd.concat([ed_texts_df[['line', 'label']], generated_lines])\n",
    "ed_texts_df['line'] = ed_texts_df['line'].apply(lambda x: re.sub(r'\\s', ' ', str(x).strip()))\n",
    "ed_texts_df['len_line'] = ed_texts_df['line'].apply(lambda x: len(x))\n",
    "#ed_texts_df = ed_texts_df[ed_texts_df['len_line'] > 100]\n",
    "ed_texts_df.drop_duplicates(inplace=True)\n",
    "ed_texts_df['first_word'] = ed_texts_df['line'].apply(lambda x: x.split(' ')[0].strip().lower())\n",
    "ed_texts_df['last_word'] = ed_texts_df['line'].apply(lambda x: x.split(' ')[-1].strip().lower())\n",
    "ed_texts_df['count_decimal'] = ed_texts_df['line'].apply(lambda x: len(re.findall(r'[0-9]+', x)))\n",
    "ed_texts_df['count_uppercased_chars'] = ed_texts_df['line'].apply(lambda x: len(re.findall(r'[A-ZA-Я]+', x)))\n",
    "ed_texts_df['count_stopwords'] = ed_texts_df['line'].apply(lambda x: len([token for token in x.split(' ') if token in stopwords.words('russian')]))\n",
    "ed_texts_df['count_puncts'] = ed_texts_df['line'].apply(lambda x: len(re.findall(r'[.,:?;!)(]*', x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hackathon/code/venv/lib/python3.7/site-packages/ipykernel_launcher.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "map_to_replace = {\n",
    "                    '3_1': 0,\n",
    "                    '3_2': 1,\n",
    "                    '3_5': 2,\n",
    "                    '3_9': 3,\n",
    "                    '4_1': 4,\n",
    "                    '4_3': 5,\n",
    "                    '3_3': 6,\n",
    "                    '3_7': 7,\n",
    "                    '4_2': 8,\n",
    "                    '3_4': 9,\n",
    "                    '3_6': 10,\n",
    "                    '3_8': 11\n",
    "                }\n",
    "\n",
    "for i in range(len(map_to_replace)):\n",
    "    feat_imp = return_feat_imp(lr, i, vectorizer)\n",
    "    ed_texts_df = create_features_from_feat_imp(ed_texts_df, feat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_texts_df.to_csv('../dataset/ed_texts_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95733, 127)\n",
      "(47243, 127)\n",
      "(48490, 127)\n"
     ]
    }
   ],
   "source": [
    "ed_texts_df = pd.read_csv('../dataset/ed_texts_df.csv')\n",
    "\n",
    "cols = list(ed_texts_df)\n",
    "cols.pop(cols.index('label'))\n",
    "ed_texts_df = ed_texts_df[(ed_texts_df['len_line'].quantile(0.10) < ed_texts_df['len_line']) & (ed_texts_df['len_line'] < ed_texts_df['len_line'].quantile(0.90))]\n",
    "\n",
    "ed_texts_df_0 = ed_texts_df[ed_texts_df['label'] == 0]\n",
    "train_ed_texts_df_0, holdout_ed_texts_df_0 = train_test_split(ed_texts_df_0, test_size=0.84, random_state=42, stratify=ed_texts_df_0['label'])\n",
    "#print(train_ed_texts_df_0.shape, holdout_ed_texts_df_0.shape)\n",
    "ed_texts_df_1 = ed_texts_df[ed_texts_df['label'] == 1]\n",
    "ed_texts_df = pd.concat([ed_texts_df_1, train_ed_texts_df_0])\n",
    "ed_texts_df.dropna(inplace=True)\n",
    "print(ed_texts_df.shape)\n",
    "print(ed_texts_df[ed_texts_df['label'] == 1].shape)\n",
    "print(ed_texts_df[ed_texts_df['label'] == 0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.069073\n",
      "0:\ttotal: 97.6ms\tremaining: 1m 37s\n",
      "1:\ttotal: 122ms\tremaining: 1m\n",
      "2:\ttotal: 151ms\tremaining: 50s\n",
      "3:\ttotal: 174ms\tremaining: 43.4s\n",
      "4:\ttotal: 197ms\tremaining: 39.1s\n",
      "5:\ttotal: 221ms\tremaining: 36.6s\n",
      "6:\ttotal: 249ms\tremaining: 35.4s\n",
      "7:\ttotal: 272ms\tremaining: 33.8s\n",
      "8:\ttotal: 295ms\tremaining: 32.5s\n",
      "9:\ttotal: 319ms\tremaining: 31.6s\n",
      "10:\ttotal: 344ms\tremaining: 30.9s\n",
      "11:\ttotal: 367ms\tremaining: 30.2s\n",
      "12:\ttotal: 391ms\tremaining: 29.7s\n",
      "13:\ttotal: 414ms\tremaining: 29.1s\n",
      "14:\ttotal: 437ms\tremaining: 28.7s\n",
      "15:\ttotal: 463ms\tremaining: 28.5s\n",
      "16:\ttotal: 486ms\tremaining: 28.1s\n",
      "17:\ttotal: 509ms\tremaining: 27.8s\n",
      "18:\ttotal: 534ms\tremaining: 27.6s\n",
      "19:\ttotal: 559ms\tremaining: 27.4s\n",
      "20:\ttotal: 581ms\tremaining: 27.1s\n",
      "21:\ttotal: 605ms\tremaining: 26.9s\n",
      "22:\ttotal: 631ms\tremaining: 26.8s\n",
      "23:\ttotal: 653ms\tremaining: 26.6s\n",
      "24:\ttotal: 677ms\tremaining: 26.4s\n",
      "25:\ttotal: 702ms\tremaining: 26.3s\n",
      "26:\ttotal: 725ms\tremaining: 26.1s\n",
      "27:\ttotal: 750ms\tremaining: 26s\n",
      "28:\ttotal: 771ms\tremaining: 25.8s\n",
      "29:\ttotal: 794ms\tremaining: 25.7s\n",
      "30:\ttotal: 816ms\tremaining: 25.5s\n",
      "31:\ttotal: 838ms\tremaining: 25.4s\n",
      "32:\ttotal: 861ms\tremaining: 25.2s\n",
      "33:\ttotal: 884ms\tremaining: 25.1s\n",
      "34:\ttotal: 908ms\tremaining: 25s\n",
      "35:\ttotal: 930ms\tremaining: 24.9s\n",
      "36:\ttotal: 956ms\tremaining: 24.9s\n",
      "37:\ttotal: 978ms\tremaining: 24.8s\n",
      "38:\ttotal: 1s\tremaining: 24.7s\n",
      "39:\ttotal: 1.03s\tremaining: 24.7s\n",
      "40:\ttotal: 1.05s\tremaining: 24.6s\n",
      "41:\ttotal: 1.07s\tremaining: 24.5s\n",
      "42:\ttotal: 1.1s\tremaining: 24.4s\n",
      "43:\ttotal: 1.12s\tremaining: 24.4s\n",
      "44:\ttotal: 1.15s\tremaining: 24.3s\n",
      "45:\ttotal: 1.17s\tremaining: 24.3s\n",
      "46:\ttotal: 1.19s\tremaining: 24.2s\n",
      "47:\ttotal: 1.22s\tremaining: 24.2s\n",
      "48:\ttotal: 1.24s\tremaining: 24.1s\n",
      "49:\ttotal: 1.27s\tremaining: 24.1s\n",
      "50:\ttotal: 1.29s\tremaining: 24s\n",
      "51:\ttotal: 1.31s\tremaining: 23.9s\n",
      "52:\ttotal: 1.33s\tremaining: 23.8s\n",
      "53:\ttotal: 1.36s\tremaining: 23.8s\n",
      "54:\ttotal: 1.38s\tremaining: 23.7s\n",
      "55:\ttotal: 1.4s\tremaining: 23.6s\n",
      "56:\ttotal: 1.42s\tremaining: 23.6s\n",
      "57:\ttotal: 1.45s\tremaining: 23.5s\n",
      "58:\ttotal: 1.47s\tremaining: 23.5s\n",
      "59:\ttotal: 1.49s\tremaining: 23.4s\n",
      "60:\ttotal: 1.52s\tremaining: 23.4s\n",
      "61:\ttotal: 1.54s\tremaining: 23.4s\n",
      "62:\ttotal: 1.57s\tremaining: 23.3s\n",
      "63:\ttotal: 1.59s\tremaining: 23.3s\n",
      "64:\ttotal: 1.61s\tremaining: 23.2s\n",
      "65:\ttotal: 1.64s\tremaining: 23.2s\n",
      "66:\ttotal: 1.66s\tremaining: 23.1s\n",
      "67:\ttotal: 1.68s\tremaining: 23.1s\n",
      "68:\ttotal: 1.71s\tremaining: 23s\n",
      "69:\ttotal: 1.73s\tremaining: 23s\n",
      "70:\ttotal: 1.75s\tremaining: 22.9s\n",
      "71:\ttotal: 1.77s\tremaining: 22.8s\n",
      "72:\ttotal: 1.8s\tremaining: 22.9s\n",
      "73:\ttotal: 1.82s\tremaining: 22.8s\n",
      "74:\ttotal: 1.84s\tremaining: 22.8s\n",
      "75:\ttotal: 1.87s\tremaining: 22.7s\n",
      "76:\ttotal: 1.89s\tremaining: 22.7s\n",
      "77:\ttotal: 1.91s\tremaining: 22.6s\n",
      "78:\ttotal: 1.93s\tremaining: 22.5s\n",
      "79:\ttotal: 1.96s\tremaining: 22.5s\n",
      "80:\ttotal: 1.98s\tremaining: 22.5s\n",
      "81:\ttotal: 2s\tremaining: 22.4s\n",
      "82:\ttotal: 2.02s\tremaining: 22.4s\n",
      "83:\ttotal: 2.05s\tremaining: 22.3s\n",
      "84:\ttotal: 2.07s\tremaining: 22.3s\n",
      "85:\ttotal: 2.09s\tremaining: 22.3s\n",
      "86:\ttotal: 2.12s\tremaining: 22.2s\n",
      "87:\ttotal: 2.14s\tremaining: 22.1s\n",
      "88:\ttotal: 2.16s\tremaining: 22.1s\n",
      "89:\ttotal: 2.18s\tremaining: 22.1s\n",
      "90:\ttotal: 2.2s\tremaining: 22s\n",
      "91:\ttotal: 2.23s\tremaining: 22s\n",
      "92:\ttotal: 2.25s\tremaining: 21.9s\n",
      "93:\ttotal: 2.27s\tremaining: 21.9s\n",
      "94:\ttotal: 2.29s\tremaining: 21.8s\n",
      "95:\ttotal: 2.31s\tremaining: 21.8s\n",
      "96:\ttotal: 2.34s\tremaining: 21.8s\n",
      "97:\ttotal: 2.37s\tremaining: 21.8s\n",
      "98:\ttotal: 2.39s\tremaining: 21.8s\n",
      "99:\ttotal: 2.41s\tremaining: 21.7s\n",
      "100:\ttotal: 2.44s\tremaining: 21.7s\n",
      "101:\ttotal: 2.46s\tremaining: 21.7s\n",
      "102:\ttotal: 2.48s\tremaining: 21.6s\n",
      "103:\ttotal: 2.5s\tremaining: 21.6s\n",
      "104:\ttotal: 2.53s\tremaining: 21.5s\n",
      "105:\ttotal: 2.55s\tremaining: 21.5s\n",
      "106:\ttotal: 2.57s\tremaining: 21.5s\n",
      "107:\ttotal: 2.59s\tremaining: 21.4s\n",
      "108:\ttotal: 2.62s\tremaining: 21.4s\n",
      "109:\ttotal: 2.64s\tremaining: 21.4s\n",
      "110:\ttotal: 2.66s\tremaining: 21.3s\n",
      "111:\ttotal: 2.68s\tremaining: 21.3s\n",
      "112:\ttotal: 2.7s\tremaining: 21.2s\n",
      "113:\ttotal: 2.72s\tremaining: 21.2s\n",
      "114:\ttotal: 2.75s\tremaining: 21.1s\n",
      "115:\ttotal: 2.77s\tremaining: 21.1s\n",
      "116:\ttotal: 2.79s\tremaining: 21s\n",
      "117:\ttotal: 2.81s\tremaining: 21s\n",
      "118:\ttotal: 2.83s\tremaining: 21s\n",
      "119:\ttotal: 2.85s\tremaining: 20.9s\n",
      "120:\ttotal: 2.88s\tremaining: 20.9s\n",
      "121:\ttotal: 2.9s\tremaining: 20.9s\n",
      "122:\ttotal: 2.92s\tremaining: 20.8s\n",
      "123:\ttotal: 2.94s\tremaining: 20.8s\n",
      "124:\ttotal: 2.96s\tremaining: 20.7s\n",
      "125:\ttotal: 2.98s\tremaining: 20.7s\n",
      "126:\ttotal: 3s\tremaining: 20.7s\n",
      "127:\ttotal: 3.03s\tremaining: 20.6s\n",
      "128:\ttotal: 3.05s\tremaining: 20.6s\n",
      "129:\ttotal: 3.07s\tremaining: 20.5s\n",
      "130:\ttotal: 3.09s\tremaining: 20.5s\n",
      "131:\ttotal: 3.11s\tremaining: 20.5s\n",
      "132:\ttotal: 3.14s\tremaining: 20.4s\n",
      "133:\ttotal: 3.16s\tremaining: 20.4s\n",
      "134:\ttotal: 3.18s\tremaining: 20.4s\n",
      "135:\ttotal: 3.21s\tremaining: 20.4s\n",
      "136:\ttotal: 3.23s\tremaining: 20.3s\n",
      "137:\ttotal: 3.25s\tremaining: 20.3s\n",
      "138:\ttotal: 3.27s\tremaining: 20.3s\n",
      "139:\ttotal: 3.29s\tremaining: 20.2s\n",
      "140:\ttotal: 3.31s\tremaining: 20.2s\n",
      "141:\ttotal: 3.34s\tremaining: 20.2s\n",
      "142:\ttotal: 3.37s\tremaining: 20.2s\n",
      "143:\ttotal: 3.39s\tremaining: 20.1s\n",
      "144:\ttotal: 3.41s\tremaining: 20.1s\n",
      "145:\ttotal: 3.43s\tremaining: 20.1s\n",
      "146:\ttotal: 3.45s\tremaining: 20s\n",
      "147:\ttotal: 3.48s\tremaining: 20s\n",
      "148:\ttotal: 3.5s\tremaining: 20s\n",
      "149:\ttotal: 3.52s\tremaining: 20s\n",
      "150:\ttotal: 3.54s\tremaining: 19.9s\n",
      "151:\ttotal: 3.56s\tremaining: 19.9s\n",
      "152:\ttotal: 3.59s\tremaining: 19.9s\n",
      "153:\ttotal: 3.61s\tremaining: 19.8s\n",
      "154:\ttotal: 3.63s\tremaining: 19.8s\n",
      "155:\ttotal: 3.65s\tremaining: 19.8s\n",
      "156:\ttotal: 3.67s\tremaining: 19.7s\n",
      "157:\ttotal: 3.69s\tremaining: 19.7s\n",
      "158:\ttotal: 3.72s\tremaining: 19.7s\n",
      "159:\ttotal: 3.74s\tremaining: 19.6s\n",
      "160:\ttotal: 3.76s\tremaining: 19.6s\n",
      "161:\ttotal: 3.78s\tremaining: 19.6s\n",
      "162:\ttotal: 3.81s\tremaining: 19.6s\n",
      "163:\ttotal: 3.83s\tremaining: 19.5s\n",
      "164:\ttotal: 3.85s\tremaining: 19.5s\n",
      "165:\ttotal: 3.87s\tremaining: 19.5s\n",
      "166:\ttotal: 3.9s\tremaining: 19.4s\n",
      "167:\ttotal: 3.92s\tremaining: 19.4s\n",
      "168:\ttotal: 3.94s\tremaining: 19.4s\n",
      "169:\ttotal: 3.96s\tremaining: 19.3s\n",
      "170:\ttotal: 3.98s\tremaining: 19.3s\n",
      "171:\ttotal: 4s\tremaining: 19.3s\n",
      "172:\ttotal: 4.03s\tremaining: 19.2s\n",
      "173:\ttotal: 4.05s\tremaining: 19.2s\n",
      "174:\ttotal: 4.07s\tremaining: 19.2s\n",
      "175:\ttotal: 4.09s\tremaining: 19.2s\n",
      "176:\ttotal: 4.11s\tremaining: 19.1s\n",
      "177:\ttotal: 4.14s\tremaining: 19.1s\n",
      "178:\ttotal: 4.16s\tremaining: 19.1s\n",
      "179:\ttotal: 4.18s\tremaining: 19s\n",
      "180:\ttotal: 4.2s\tremaining: 19s\n",
      "181:\ttotal: 4.22s\tremaining: 19s\n",
      "182:\ttotal: 4.25s\tremaining: 19s\n",
      "183:\ttotal: 4.27s\tremaining: 18.9s\n",
      "184:\ttotal: 4.29s\tremaining: 18.9s\n",
      "185:\ttotal: 4.32s\tremaining: 18.9s\n",
      "186:\ttotal: 4.34s\tremaining: 18.9s\n",
      "187:\ttotal: 4.36s\tremaining: 18.9s\n",
      "188:\ttotal: 4.39s\tremaining: 18.8s\n",
      "189:\ttotal: 4.41s\tremaining: 18.8s\n",
      "190:\ttotal: 4.43s\tremaining: 18.8s\n",
      "191:\ttotal: 4.46s\tremaining: 18.8s\n",
      "192:\ttotal: 4.48s\tremaining: 18.7s\n",
      "193:\ttotal: 4.5s\tremaining: 18.7s\n",
      "194:\ttotal: 4.52s\tremaining: 18.7s\n",
      "195:\ttotal: 4.54s\tremaining: 18.6s\n",
      "196:\ttotal: 4.57s\tremaining: 18.6s\n",
      "197:\ttotal: 4.59s\tremaining: 18.6s\n",
      "198:\ttotal: 4.61s\tremaining: 18.6s\n",
      "199:\ttotal: 4.63s\tremaining: 18.5s\n",
      "200:\ttotal: 4.66s\tremaining: 18.5s\n",
      "201:\ttotal: 4.68s\tremaining: 18.5s\n",
      "202:\ttotal: 4.7s\tremaining: 18.5s\n",
      "203:\ttotal: 4.72s\tremaining: 18.4s\n",
      "204:\ttotal: 4.75s\tremaining: 18.4s\n",
      "205:\ttotal: 4.77s\tremaining: 18.4s\n",
      "206:\ttotal: 4.79s\tremaining: 18.4s\n",
      "207:\ttotal: 4.81s\tremaining: 18.3s\n",
      "208:\ttotal: 4.84s\tremaining: 18.3s\n",
      "209:\ttotal: 4.86s\tremaining: 18.3s\n",
      "210:\ttotal: 4.88s\tremaining: 18.3s\n",
      "211:\ttotal: 4.9s\tremaining: 18.2s\n",
      "212:\ttotal: 4.93s\tremaining: 18.2s\n",
      "213:\ttotal: 4.95s\tremaining: 18.2s\n",
      "214:\ttotal: 4.97s\tremaining: 18.2s\n",
      "215:\ttotal: 5s\tremaining: 18.1s\n",
      "216:\ttotal: 5.02s\tremaining: 18.1s\n",
      "217:\ttotal: 5.04s\tremaining: 18.1s\n",
      "218:\ttotal: 5.06s\tremaining: 18.1s\n",
      "219:\ttotal: 5.08s\tremaining: 18s\n",
      "220:\ttotal: 5.1s\tremaining: 18s\n",
      "221:\ttotal: 5.12s\tremaining: 18s\n",
      "222:\ttotal: 5.15s\tremaining: 17.9s\n",
      "223:\ttotal: 5.17s\tremaining: 17.9s\n",
      "224:\ttotal: 5.19s\tremaining: 17.9s\n",
      "225:\ttotal: 5.22s\tremaining: 17.9s\n",
      "226:\ttotal: 5.24s\tremaining: 17.8s\n",
      "227:\ttotal: 5.26s\tremaining: 17.8s\n",
      "228:\ttotal: 5.28s\tremaining: 17.8s\n",
      "229:\ttotal: 5.31s\tremaining: 17.8s\n",
      "230:\ttotal: 5.33s\tremaining: 17.7s\n",
      "231:\ttotal: 5.35s\tremaining: 17.7s\n",
      "232:\ttotal: 5.38s\tremaining: 17.7s\n",
      "233:\ttotal: 5.4s\tremaining: 17.7s\n",
      "234:\ttotal: 5.42s\tremaining: 17.7s\n",
      "235:\ttotal: 5.45s\tremaining: 17.6s\n",
      "236:\ttotal: 5.47s\tremaining: 17.6s\n",
      "237:\ttotal: 5.49s\tremaining: 17.6s\n",
      "238:\ttotal: 5.52s\tremaining: 17.6s\n",
      "239:\ttotal: 5.54s\tremaining: 17.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240:\ttotal: 5.56s\tremaining: 17.5s\n",
      "241:\ttotal: 5.58s\tremaining: 17.5s\n",
      "242:\ttotal: 5.61s\tremaining: 17.5s\n",
      "243:\ttotal: 5.63s\tremaining: 17.4s\n",
      "244:\ttotal: 5.65s\tremaining: 17.4s\n",
      "245:\ttotal: 5.67s\tremaining: 17.4s\n",
      "246:\ttotal: 5.7s\tremaining: 17.4s\n",
      "247:\ttotal: 5.72s\tremaining: 17.3s\n",
      "248:\ttotal: 5.74s\tremaining: 17.3s\n",
      "249:\ttotal: 5.76s\tremaining: 17.3s\n",
      "250:\ttotal: 5.79s\tremaining: 17.3s\n",
      "251:\ttotal: 5.81s\tremaining: 17.2s\n",
      "252:\ttotal: 5.83s\tremaining: 17.2s\n",
      "253:\ttotal: 5.85s\tremaining: 17.2s\n",
      "254:\ttotal: 5.87s\tremaining: 17.2s\n",
      "255:\ttotal: 5.9s\tremaining: 17.1s\n",
      "256:\ttotal: 5.92s\tremaining: 17.1s\n",
      "257:\ttotal: 5.94s\tremaining: 17.1s\n",
      "258:\ttotal: 5.96s\tremaining: 17.1s\n",
      "259:\ttotal: 5.99s\tremaining: 17s\n",
      "260:\ttotal: 6.01s\tremaining: 17s\n",
      "261:\ttotal: 6.03s\tremaining: 17s\n",
      "262:\ttotal: 6.05s\tremaining: 17s\n",
      "263:\ttotal: 6.08s\tremaining: 16.9s\n",
      "264:\ttotal: 6.1s\tremaining: 16.9s\n",
      "265:\ttotal: 6.12s\tremaining: 16.9s\n",
      "266:\ttotal: 6.14s\tremaining: 16.9s\n",
      "267:\ttotal: 6.16s\tremaining: 16.8s\n",
      "268:\ttotal: 6.18s\tremaining: 16.8s\n",
      "269:\ttotal: 6.21s\tremaining: 16.8s\n",
      "270:\ttotal: 6.23s\tremaining: 16.8s\n",
      "271:\ttotal: 6.25s\tremaining: 16.7s\n",
      "272:\ttotal: 6.27s\tremaining: 16.7s\n",
      "273:\ttotal: 6.29s\tremaining: 16.7s\n",
      "274:\ttotal: 6.32s\tremaining: 16.7s\n",
      "275:\ttotal: 6.34s\tremaining: 16.6s\n",
      "276:\ttotal: 6.37s\tremaining: 16.6s\n",
      "277:\ttotal: 6.39s\tremaining: 16.6s\n",
      "278:\ttotal: 6.41s\tremaining: 16.6s\n",
      "279:\ttotal: 6.43s\tremaining: 16.5s\n",
      "280:\ttotal: 6.46s\tremaining: 16.5s\n",
      "281:\ttotal: 6.48s\tremaining: 16.5s\n",
      "282:\ttotal: 6.5s\tremaining: 16.5s\n",
      "283:\ttotal: 6.52s\tremaining: 16.4s\n",
      "284:\ttotal: 6.54s\tremaining: 16.4s\n",
      "285:\ttotal: 6.56s\tremaining: 16.4s\n",
      "286:\ttotal: 6.58s\tremaining: 16.4s\n",
      "287:\ttotal: 6.61s\tremaining: 16.3s\n",
      "288:\ttotal: 6.63s\tremaining: 16.3s\n",
      "289:\ttotal: 6.65s\tremaining: 16.3s\n",
      "290:\ttotal: 6.68s\tremaining: 16.3s\n",
      "291:\ttotal: 6.7s\tremaining: 16.2s\n",
      "292:\ttotal: 6.72s\tremaining: 16.2s\n",
      "293:\ttotal: 6.74s\tremaining: 16.2s\n",
      "294:\ttotal: 6.76s\tremaining: 16.2s\n",
      "295:\ttotal: 6.78s\tremaining: 16.1s\n",
      "296:\ttotal: 6.8s\tremaining: 16.1s\n",
      "297:\ttotal: 6.83s\tremaining: 16.1s\n",
      "298:\ttotal: 6.85s\tremaining: 16.1s\n",
      "299:\ttotal: 6.87s\tremaining: 16s\n",
      "300:\ttotal: 6.9s\tremaining: 16s\n",
      "301:\ttotal: 6.92s\tremaining: 16s\n",
      "302:\ttotal: 6.94s\tremaining: 16s\n",
      "303:\ttotal: 6.97s\tremaining: 16s\n",
      "304:\ttotal: 6.99s\tremaining: 15.9s\n",
      "305:\ttotal: 7.01s\tremaining: 15.9s\n",
      "306:\ttotal: 7.04s\tremaining: 15.9s\n",
      "307:\ttotal: 7.06s\tremaining: 15.9s\n",
      "308:\ttotal: 7.08s\tremaining: 15.8s\n",
      "309:\ttotal: 7.1s\tremaining: 15.8s\n",
      "310:\ttotal: 7.13s\tremaining: 15.8s\n",
      "311:\ttotal: 7.15s\tremaining: 15.8s\n",
      "312:\ttotal: 7.17s\tremaining: 15.7s\n",
      "313:\ttotal: 7.2s\tremaining: 15.7s\n",
      "314:\ttotal: 7.22s\tremaining: 15.7s\n",
      "315:\ttotal: 7.24s\tremaining: 15.7s\n",
      "316:\ttotal: 7.26s\tremaining: 15.6s\n",
      "317:\ttotal: 7.28s\tremaining: 15.6s\n",
      "318:\ttotal: 7.3s\tremaining: 15.6s\n",
      "319:\ttotal: 7.32s\tremaining: 15.6s\n",
      "320:\ttotal: 7.34s\tremaining: 15.5s\n",
      "321:\ttotal: 7.37s\tremaining: 15.5s\n",
      "322:\ttotal: 7.39s\tremaining: 15.5s\n",
      "323:\ttotal: 7.41s\tremaining: 15.5s\n",
      "324:\ttotal: 7.43s\tremaining: 15.4s\n",
      "325:\ttotal: 7.46s\tremaining: 15.4s\n",
      "326:\ttotal: 7.48s\tremaining: 15.4s\n",
      "327:\ttotal: 7.5s\tremaining: 15.4s\n",
      "328:\ttotal: 7.52s\tremaining: 15.3s\n",
      "329:\ttotal: 7.55s\tremaining: 15.3s\n",
      "330:\ttotal: 7.57s\tremaining: 15.3s\n",
      "331:\ttotal: 7.59s\tremaining: 15.3s\n",
      "332:\ttotal: 7.61s\tremaining: 15.2s\n",
      "333:\ttotal: 7.63s\tremaining: 15.2s\n",
      "334:\ttotal: 7.65s\tremaining: 15.2s\n",
      "335:\ttotal: 7.68s\tremaining: 15.2s\n",
      "336:\ttotal: 7.7s\tremaining: 15.1s\n",
      "337:\ttotal: 7.72s\tremaining: 15.1s\n",
      "338:\ttotal: 7.74s\tremaining: 15.1s\n",
      "339:\ttotal: 7.77s\tremaining: 15.1s\n",
      "340:\ttotal: 7.79s\tremaining: 15.1s\n",
      "341:\ttotal: 7.81s\tremaining: 15s\n",
      "342:\ttotal: 7.84s\tremaining: 15s\n",
      "343:\ttotal: 7.86s\tremaining: 15s\n",
      "344:\ttotal: 7.88s\tremaining: 15s\n",
      "345:\ttotal: 7.9s\tremaining: 14.9s\n",
      "346:\ttotal: 7.93s\tremaining: 14.9s\n",
      "347:\ttotal: 7.95s\tremaining: 14.9s\n",
      "348:\ttotal: 7.97s\tremaining: 14.9s\n",
      "349:\ttotal: 7.99s\tremaining: 14.8s\n",
      "350:\ttotal: 8.01s\tremaining: 14.8s\n",
      "351:\ttotal: 8.04s\tremaining: 14.8s\n",
      "352:\ttotal: 8.06s\tremaining: 14.8s\n",
      "353:\ttotal: 8.08s\tremaining: 14.7s\n",
      "354:\ttotal: 8.11s\tremaining: 14.7s\n",
      "355:\ttotal: 8.13s\tremaining: 14.7s\n",
      "356:\ttotal: 8.15s\tremaining: 14.7s\n",
      "357:\ttotal: 8.17s\tremaining: 14.7s\n",
      "358:\ttotal: 8.19s\tremaining: 14.6s\n",
      "359:\ttotal: 8.21s\tremaining: 14.6s\n",
      "360:\ttotal: 8.24s\tremaining: 14.6s\n",
      "361:\ttotal: 8.26s\tremaining: 14.6s\n",
      "362:\ttotal: 8.29s\tremaining: 14.5s\n",
      "363:\ttotal: 8.31s\tremaining: 14.5s\n",
      "364:\ttotal: 8.33s\tremaining: 14.5s\n",
      "365:\ttotal: 8.36s\tremaining: 14.5s\n",
      "366:\ttotal: 8.38s\tremaining: 14.5s\n",
      "367:\ttotal: 8.4s\tremaining: 14.4s\n",
      "368:\ttotal: 8.42s\tremaining: 14.4s\n",
      "369:\ttotal: 8.45s\tremaining: 14.4s\n",
      "370:\ttotal: 8.47s\tremaining: 14.4s\n",
      "371:\ttotal: 8.49s\tremaining: 14.3s\n",
      "372:\ttotal: 8.51s\tremaining: 14.3s\n",
      "373:\ttotal: 8.54s\tremaining: 14.3s\n",
      "374:\ttotal: 8.56s\tremaining: 14.3s\n",
      "375:\ttotal: 8.59s\tremaining: 14.2s\n",
      "376:\ttotal: 8.61s\tremaining: 14.2s\n",
      "377:\ttotal: 8.63s\tremaining: 14.2s\n",
      "378:\ttotal: 8.65s\tremaining: 14.2s\n",
      "379:\ttotal: 8.67s\tremaining: 14.2s\n",
      "380:\ttotal: 8.7s\tremaining: 14.1s\n",
      "381:\ttotal: 8.72s\tremaining: 14.1s\n",
      "382:\ttotal: 8.74s\tremaining: 14.1s\n",
      "383:\ttotal: 8.77s\tremaining: 14.1s\n",
      "384:\ttotal: 8.79s\tremaining: 14s\n",
      "385:\ttotal: 8.81s\tremaining: 14s\n",
      "386:\ttotal: 8.84s\tremaining: 14s\n",
      "387:\ttotal: 8.86s\tremaining: 14s\n",
      "388:\ttotal: 8.88s\tremaining: 14s\n",
      "389:\ttotal: 8.91s\tremaining: 13.9s\n",
      "390:\ttotal: 8.93s\tremaining: 13.9s\n",
      "391:\ttotal: 8.95s\tremaining: 13.9s\n",
      "392:\ttotal: 8.97s\tremaining: 13.9s\n",
      "393:\ttotal: 8.99s\tremaining: 13.8s\n",
      "394:\ttotal: 9.01s\tremaining: 13.8s\n",
      "395:\ttotal: 9.04s\tremaining: 13.8s\n",
      "396:\ttotal: 9.06s\tremaining: 13.8s\n",
      "397:\ttotal: 9.09s\tremaining: 13.7s\n",
      "398:\ttotal: 9.11s\tremaining: 13.7s\n",
      "399:\ttotal: 9.13s\tremaining: 13.7s\n",
      "400:\ttotal: 9.15s\tremaining: 13.7s\n",
      "401:\ttotal: 9.17s\tremaining: 13.6s\n",
      "402:\ttotal: 9.19s\tremaining: 13.6s\n",
      "403:\ttotal: 9.22s\tremaining: 13.6s\n",
      "404:\ttotal: 9.24s\tremaining: 13.6s\n",
      "405:\ttotal: 9.26s\tremaining: 13.5s\n",
      "406:\ttotal: 9.28s\tremaining: 13.5s\n",
      "407:\ttotal: 9.3s\tremaining: 13.5s\n",
      "408:\ttotal: 9.33s\tremaining: 13.5s\n",
      "409:\ttotal: 9.35s\tremaining: 13.5s\n",
      "410:\ttotal: 9.38s\tremaining: 13.4s\n",
      "411:\ttotal: 9.4s\tremaining: 13.4s\n",
      "412:\ttotal: 9.42s\tremaining: 13.4s\n",
      "413:\ttotal: 9.44s\tremaining: 13.4s\n",
      "414:\ttotal: 9.46s\tremaining: 13.3s\n",
      "415:\ttotal: 9.49s\tremaining: 13.3s\n",
      "416:\ttotal: 9.51s\tremaining: 13.3s\n",
      "417:\ttotal: 9.53s\tremaining: 13.3s\n",
      "418:\ttotal: 9.55s\tremaining: 13.2s\n",
      "419:\ttotal: 9.57s\tremaining: 13.2s\n",
      "420:\ttotal: 9.6s\tremaining: 13.2s\n",
      "421:\ttotal: 9.62s\tremaining: 13.2s\n",
      "422:\ttotal: 9.64s\tremaining: 13.1s\n",
      "423:\ttotal: 9.66s\tremaining: 13.1s\n",
      "424:\ttotal: 9.69s\tremaining: 13.1s\n",
      "425:\ttotal: 9.71s\tremaining: 13.1s\n",
      "426:\ttotal: 9.73s\tremaining: 13.1s\n",
      "427:\ttotal: 9.76s\tremaining: 13s\n",
      "428:\ttotal: 9.78s\tremaining: 13s\n",
      "429:\ttotal: 9.8s\tremaining: 13s\n",
      "430:\ttotal: 9.82s\tremaining: 13s\n",
      "431:\ttotal: 9.84s\tremaining: 12.9s\n",
      "432:\ttotal: 9.87s\tremaining: 12.9s\n",
      "433:\ttotal: 9.89s\tremaining: 12.9s\n",
      "434:\ttotal: 9.91s\tremaining: 12.9s\n",
      "435:\ttotal: 9.94s\tremaining: 12.9s\n",
      "436:\ttotal: 9.96s\tremaining: 12.8s\n",
      "437:\ttotal: 9.98s\tremaining: 12.8s\n",
      "438:\ttotal: 10s\tremaining: 12.8s\n",
      "439:\ttotal: 10s\tremaining: 12.8s\n",
      "440:\ttotal: 10.1s\tremaining: 12.7s\n",
      "441:\ttotal: 10.1s\tremaining: 12.7s\n",
      "442:\ttotal: 10.1s\tremaining: 12.7s\n",
      "443:\ttotal: 10.1s\tremaining: 12.7s\n",
      "444:\ttotal: 10.1s\tremaining: 12.7s\n",
      "445:\ttotal: 10.2s\tremaining: 12.6s\n",
      "446:\ttotal: 10.2s\tremaining: 12.6s\n",
      "447:\ttotal: 10.2s\tremaining: 12.6s\n",
      "448:\ttotal: 10.2s\tremaining: 12.6s\n",
      "449:\ttotal: 10.3s\tremaining: 12.5s\n",
      "450:\ttotal: 10.3s\tremaining: 12.5s\n",
      "451:\ttotal: 10.3s\tremaining: 12.5s\n",
      "452:\ttotal: 10.3s\tremaining: 12.5s\n",
      "453:\ttotal: 10.3s\tremaining: 12.4s\n",
      "454:\ttotal: 10.4s\tremaining: 12.4s\n",
      "455:\ttotal: 10.4s\tremaining: 12.4s\n",
      "456:\ttotal: 10.4s\tremaining: 12.4s\n",
      "457:\ttotal: 10.4s\tremaining: 12.4s\n",
      "458:\ttotal: 10.5s\tremaining: 12.3s\n",
      "459:\ttotal: 10.5s\tremaining: 12.3s\n",
      "460:\ttotal: 10.5s\tremaining: 12.3s\n",
      "461:\ttotal: 10.5s\tremaining: 12.3s\n",
      "462:\ttotal: 10.6s\tremaining: 12.2s\n",
      "463:\ttotal: 10.6s\tremaining: 12.2s\n",
      "464:\ttotal: 10.6s\tremaining: 12.2s\n",
      "465:\ttotal: 10.6s\tremaining: 12.2s\n",
      "466:\ttotal: 10.6s\tremaining: 12.1s\n",
      "467:\ttotal: 10.7s\tremaining: 12.1s\n",
      "468:\ttotal: 10.7s\tremaining: 12.1s\n",
      "469:\ttotal: 10.7s\tremaining: 12.1s\n",
      "470:\ttotal: 10.7s\tremaining: 12.1s\n",
      "471:\ttotal: 10.8s\tremaining: 12s\n",
      "472:\ttotal: 10.8s\tremaining: 12s\n",
      "473:\ttotal: 10.8s\tremaining: 12s\n",
      "474:\ttotal: 10.8s\tremaining: 12s\n",
      "475:\ttotal: 10.8s\tremaining: 11.9s\n",
      "476:\ttotal: 10.9s\tremaining: 11.9s\n",
      "477:\ttotal: 10.9s\tremaining: 11.9s\n",
      "478:\ttotal: 10.9s\tremaining: 11.9s\n",
      "479:\ttotal: 10.9s\tremaining: 11.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480:\ttotal: 11s\tremaining: 11.8s\n",
      "481:\ttotal: 11s\tremaining: 11.8s\n",
      "482:\ttotal: 11s\tremaining: 11.8s\n",
      "483:\ttotal: 11s\tremaining: 11.8s\n",
      "484:\ttotal: 11s\tremaining: 11.7s\n",
      "485:\ttotal: 11.1s\tremaining: 11.7s\n",
      "486:\ttotal: 11.1s\tremaining: 11.7s\n",
      "487:\ttotal: 11.1s\tremaining: 11.7s\n",
      "488:\ttotal: 11.1s\tremaining: 11.6s\n",
      "489:\ttotal: 11.2s\tremaining: 11.6s\n",
      "490:\ttotal: 11.2s\tremaining: 11.6s\n",
      "491:\ttotal: 11.2s\tremaining: 11.6s\n",
      "492:\ttotal: 11.2s\tremaining: 11.5s\n",
      "493:\ttotal: 11.2s\tremaining: 11.5s\n",
      "494:\ttotal: 11.3s\tremaining: 11.5s\n",
      "495:\ttotal: 11.3s\tremaining: 11.5s\n",
      "496:\ttotal: 11.3s\tremaining: 11.5s\n",
      "497:\ttotal: 11.3s\tremaining: 11.4s\n",
      "498:\ttotal: 11.4s\tremaining: 11.4s\n",
      "499:\ttotal: 11.4s\tremaining: 11.4s\n",
      "500:\ttotal: 11.4s\tremaining: 11.4s\n",
      "501:\ttotal: 11.4s\tremaining: 11.3s\n",
      "502:\ttotal: 11.5s\tremaining: 11.3s\n",
      "503:\ttotal: 11.5s\tremaining: 11.3s\n",
      "504:\ttotal: 11.5s\tremaining: 11.3s\n",
      "505:\ttotal: 11.5s\tremaining: 11.2s\n",
      "506:\ttotal: 11.5s\tremaining: 11.2s\n",
      "507:\ttotal: 11.6s\tremaining: 11.2s\n",
      "508:\ttotal: 11.6s\tremaining: 11.2s\n",
      "509:\ttotal: 11.6s\tremaining: 11.2s\n",
      "510:\ttotal: 11.6s\tremaining: 11.1s\n",
      "511:\ttotal: 11.7s\tremaining: 11.1s\n",
      "512:\ttotal: 11.7s\tremaining: 11.1s\n",
      "513:\ttotal: 11.7s\tremaining: 11.1s\n",
      "514:\ttotal: 11.7s\tremaining: 11s\n",
      "515:\ttotal: 11.7s\tremaining: 11s\n",
      "516:\ttotal: 11.8s\tremaining: 11s\n",
      "517:\ttotal: 11.8s\tremaining: 11s\n",
      "518:\ttotal: 11.8s\tremaining: 10.9s\n",
      "519:\ttotal: 11.8s\tremaining: 10.9s\n",
      "520:\ttotal: 11.9s\tremaining: 10.9s\n",
      "521:\ttotal: 11.9s\tremaining: 10.9s\n",
      "522:\ttotal: 11.9s\tremaining: 10.9s\n",
      "523:\ttotal: 11.9s\tremaining: 10.8s\n",
      "524:\ttotal: 11.9s\tremaining: 10.8s\n",
      "525:\ttotal: 12s\tremaining: 10.8s\n",
      "526:\ttotal: 12s\tremaining: 10.8s\n",
      "527:\ttotal: 12s\tremaining: 10.7s\n",
      "528:\ttotal: 12s\tremaining: 10.7s\n",
      "529:\ttotal: 12.1s\tremaining: 10.7s\n",
      "530:\ttotal: 12.1s\tremaining: 10.7s\n",
      "531:\ttotal: 12.1s\tremaining: 10.6s\n",
      "532:\ttotal: 12.1s\tremaining: 10.6s\n",
      "533:\ttotal: 12.2s\tremaining: 10.6s\n",
      "534:\ttotal: 12.2s\tremaining: 10.6s\n",
      "535:\ttotal: 12.2s\tremaining: 10.6s\n",
      "536:\ttotal: 12.2s\tremaining: 10.5s\n",
      "537:\ttotal: 12.2s\tremaining: 10.5s\n",
      "538:\ttotal: 12.3s\tremaining: 10.5s\n",
      "539:\ttotal: 12.3s\tremaining: 10.5s\n",
      "540:\ttotal: 12.3s\tremaining: 10.4s\n",
      "541:\ttotal: 12.3s\tremaining: 10.4s\n",
      "542:\ttotal: 12.4s\tremaining: 10.4s\n",
      "543:\ttotal: 12.4s\tremaining: 10.4s\n",
      "544:\ttotal: 12.4s\tremaining: 10.4s\n",
      "545:\ttotal: 12.4s\tremaining: 10.3s\n",
      "546:\ttotal: 12.5s\tremaining: 10.3s\n",
      "547:\ttotal: 12.5s\tremaining: 10.3s\n",
      "548:\ttotal: 12.5s\tremaining: 10.3s\n",
      "549:\ttotal: 12.5s\tremaining: 10.2s\n",
      "550:\ttotal: 12.5s\tremaining: 10.2s\n",
      "551:\ttotal: 12.6s\tremaining: 10.2s\n",
      "552:\ttotal: 12.6s\tremaining: 10.2s\n",
      "553:\ttotal: 12.6s\tremaining: 10.1s\n",
      "554:\ttotal: 12.6s\tremaining: 10.1s\n",
      "555:\ttotal: 12.6s\tremaining: 10.1s\n",
      "556:\ttotal: 12.7s\tremaining: 10.1s\n",
      "557:\ttotal: 12.7s\tremaining: 10.1s\n",
      "558:\ttotal: 12.7s\tremaining: 10s\n",
      "559:\ttotal: 12.7s\tremaining: 10s\n",
      "560:\ttotal: 12.8s\tremaining: 9.98s\n",
      "561:\ttotal: 12.8s\tremaining: 9.96s\n",
      "562:\ttotal: 12.8s\tremaining: 9.94s\n",
      "563:\ttotal: 12.8s\tremaining: 9.91s\n",
      "564:\ttotal: 12.8s\tremaining: 9.89s\n",
      "565:\ttotal: 12.9s\tremaining: 9.87s\n",
      "566:\ttotal: 12.9s\tremaining: 9.85s\n",
      "567:\ttotal: 12.9s\tremaining: 9.82s\n",
      "568:\ttotal: 12.9s\tremaining: 9.8s\n",
      "569:\ttotal: 13s\tremaining: 9.78s\n",
      "570:\ttotal: 13s\tremaining: 9.75s\n",
      "571:\ttotal: 13s\tremaining: 9.73s\n",
      "572:\ttotal: 13s\tremaining: 9.71s\n",
      "573:\ttotal: 13s\tremaining: 9.68s\n",
      "574:\ttotal: 13.1s\tremaining: 9.66s\n",
      "575:\ttotal: 13.1s\tremaining: 9.64s\n",
      "576:\ttotal: 13.1s\tremaining: 9.61s\n",
      "577:\ttotal: 13.1s\tremaining: 9.59s\n",
      "578:\ttotal: 13.2s\tremaining: 9.57s\n",
      "579:\ttotal: 13.2s\tremaining: 9.54s\n",
      "580:\ttotal: 13.2s\tremaining: 9.52s\n",
      "581:\ttotal: 13.2s\tremaining: 9.5s\n",
      "582:\ttotal: 13.2s\tremaining: 9.47s\n",
      "583:\ttotal: 13.3s\tremaining: 9.45s\n",
      "584:\ttotal: 13.3s\tremaining: 9.43s\n",
      "585:\ttotal: 13.3s\tremaining: 9.41s\n",
      "586:\ttotal: 13.3s\tremaining: 9.39s\n",
      "587:\ttotal: 13.4s\tremaining: 9.37s\n",
      "588:\ttotal: 13.4s\tremaining: 9.34s\n",
      "589:\ttotal: 13.4s\tremaining: 9.32s\n",
      "590:\ttotal: 13.4s\tremaining: 9.29s\n",
      "591:\ttotal: 13.4s\tremaining: 9.27s\n",
      "592:\ttotal: 13.5s\tremaining: 9.24s\n",
      "593:\ttotal: 13.5s\tremaining: 9.22s\n",
      "594:\ttotal: 13.5s\tremaining: 9.2s\n",
      "595:\ttotal: 13.5s\tremaining: 9.18s\n",
      "596:\ttotal: 13.6s\tremaining: 9.15s\n",
      "597:\ttotal: 13.6s\tremaining: 9.13s\n",
      "598:\ttotal: 13.6s\tremaining: 9.11s\n",
      "599:\ttotal: 13.6s\tremaining: 9.08s\n",
      "600:\ttotal: 13.6s\tremaining: 9.06s\n",
      "601:\ttotal: 13.7s\tremaining: 9.04s\n",
      "602:\ttotal: 13.7s\tremaining: 9.02s\n",
      "603:\ttotal: 13.7s\tremaining: 8.99s\n",
      "604:\ttotal: 13.7s\tremaining: 8.97s\n",
      "605:\ttotal: 13.8s\tremaining: 8.95s\n",
      "606:\ttotal: 13.8s\tremaining: 8.93s\n",
      "607:\ttotal: 13.8s\tremaining: 8.9s\n",
      "608:\ttotal: 13.8s\tremaining: 8.88s\n",
      "609:\ttotal: 13.9s\tremaining: 8.86s\n",
      "610:\ttotal: 13.9s\tremaining: 8.84s\n",
      "611:\ttotal: 13.9s\tremaining: 8.82s\n",
      "612:\ttotal: 13.9s\tremaining: 8.79s\n",
      "613:\ttotal: 13.9s\tremaining: 8.77s\n",
      "614:\ttotal: 14s\tremaining: 8.75s\n",
      "615:\ttotal: 14s\tremaining: 8.72s\n",
      "616:\ttotal: 14s\tremaining: 8.7s\n",
      "617:\ttotal: 14s\tremaining: 8.68s\n",
      "618:\ttotal: 14.1s\tremaining: 8.65s\n",
      "619:\ttotal: 14.1s\tremaining: 8.63s\n",
      "620:\ttotal: 14.1s\tremaining: 8.61s\n",
      "621:\ttotal: 14.1s\tremaining: 8.58s\n",
      "622:\ttotal: 14.2s\tremaining: 8.56s\n",
      "623:\ttotal: 14.2s\tremaining: 8.54s\n",
      "624:\ttotal: 14.2s\tremaining: 8.52s\n",
      "625:\ttotal: 14.2s\tremaining: 8.49s\n",
      "626:\ttotal: 14.2s\tremaining: 8.47s\n",
      "627:\ttotal: 14.3s\tremaining: 8.45s\n",
      "628:\ttotal: 14.3s\tremaining: 8.42s\n",
      "629:\ttotal: 14.3s\tremaining: 8.4s\n",
      "630:\ttotal: 14.3s\tremaining: 8.38s\n",
      "631:\ttotal: 14.3s\tremaining: 8.35s\n",
      "632:\ttotal: 14.4s\tremaining: 8.33s\n",
      "633:\ttotal: 14.4s\tremaining: 8.31s\n",
      "634:\ttotal: 14.4s\tremaining: 8.29s\n",
      "635:\ttotal: 14.4s\tremaining: 8.27s\n",
      "636:\ttotal: 14.5s\tremaining: 8.24s\n",
      "637:\ttotal: 14.5s\tremaining: 8.22s\n",
      "638:\ttotal: 14.5s\tremaining: 8.19s\n",
      "639:\ttotal: 14.5s\tremaining: 8.17s\n",
      "640:\ttotal: 14.6s\tremaining: 8.15s\n",
      "641:\ttotal: 14.6s\tremaining: 8.13s\n",
      "642:\ttotal: 14.6s\tremaining: 8.1s\n",
      "643:\ttotal: 14.6s\tremaining: 8.08s\n",
      "644:\ttotal: 14.6s\tremaining: 8.06s\n",
      "645:\ttotal: 14.7s\tremaining: 8.04s\n",
      "646:\ttotal: 14.7s\tremaining: 8.01s\n",
      "647:\ttotal: 14.7s\tremaining: 7.99s\n",
      "648:\ttotal: 14.7s\tremaining: 7.97s\n",
      "649:\ttotal: 14.8s\tremaining: 7.95s\n",
      "650:\ttotal: 14.8s\tremaining: 7.92s\n",
      "651:\ttotal: 14.8s\tremaining: 7.9s\n",
      "652:\ttotal: 14.8s\tremaining: 7.88s\n",
      "653:\ttotal: 14.8s\tremaining: 7.85s\n",
      "654:\ttotal: 14.9s\tremaining: 7.83s\n",
      "655:\ttotal: 14.9s\tremaining: 7.81s\n",
      "656:\ttotal: 14.9s\tremaining: 7.78s\n",
      "657:\ttotal: 14.9s\tremaining: 7.76s\n",
      "658:\ttotal: 15s\tremaining: 7.74s\n",
      "659:\ttotal: 15s\tremaining: 7.72s\n",
      "660:\ttotal: 15s\tremaining: 7.69s\n",
      "661:\ttotal: 15s\tremaining: 7.67s\n",
      "662:\ttotal: 15s\tremaining: 7.65s\n",
      "663:\ttotal: 15.1s\tremaining: 7.62s\n",
      "664:\ttotal: 15.1s\tremaining: 7.6s\n",
      "665:\ttotal: 15.1s\tremaining: 7.58s\n",
      "666:\ttotal: 15.1s\tremaining: 7.56s\n",
      "667:\ttotal: 15.2s\tremaining: 7.53s\n",
      "668:\ttotal: 15.2s\tremaining: 7.51s\n",
      "669:\ttotal: 15.2s\tremaining: 7.49s\n",
      "670:\ttotal: 15.2s\tremaining: 7.46s\n",
      "671:\ttotal: 15.2s\tremaining: 7.44s\n",
      "672:\ttotal: 15.3s\tremaining: 7.42s\n",
      "673:\ttotal: 15.3s\tremaining: 7.39s\n",
      "674:\ttotal: 15.3s\tremaining: 7.37s\n",
      "675:\ttotal: 15.3s\tremaining: 7.35s\n",
      "676:\ttotal: 15.4s\tremaining: 7.33s\n",
      "677:\ttotal: 15.4s\tremaining: 7.3s\n",
      "678:\ttotal: 15.4s\tremaining: 7.28s\n",
      "679:\ttotal: 15.4s\tremaining: 7.26s\n",
      "680:\ttotal: 15.4s\tremaining: 7.24s\n",
      "681:\ttotal: 15.5s\tremaining: 7.21s\n",
      "682:\ttotal: 15.5s\tremaining: 7.19s\n",
      "683:\ttotal: 15.5s\tremaining: 7.17s\n",
      "684:\ttotal: 15.5s\tremaining: 7.15s\n",
      "685:\ttotal: 15.6s\tremaining: 7.13s\n",
      "686:\ttotal: 15.6s\tremaining: 7.1s\n",
      "687:\ttotal: 15.6s\tremaining: 7.08s\n",
      "688:\ttotal: 15.6s\tremaining: 7.05s\n",
      "689:\ttotal: 15.7s\tremaining: 7.03s\n",
      "690:\ttotal: 15.7s\tremaining: 7.01s\n",
      "691:\ttotal: 15.7s\tremaining: 6.99s\n",
      "692:\ttotal: 15.7s\tremaining: 6.96s\n",
      "693:\ttotal: 15.7s\tremaining: 6.94s\n",
      "694:\ttotal: 15.8s\tremaining: 6.92s\n",
      "695:\ttotal: 15.8s\tremaining: 6.89s\n",
      "696:\ttotal: 15.8s\tremaining: 6.87s\n",
      "697:\ttotal: 15.8s\tremaining: 6.85s\n",
      "698:\ttotal: 15.9s\tremaining: 6.83s\n",
      "699:\ttotal: 15.9s\tremaining: 6.8s\n",
      "700:\ttotal: 15.9s\tremaining: 6.78s\n",
      "701:\ttotal: 15.9s\tremaining: 6.76s\n",
      "702:\ttotal: 15.9s\tremaining: 6.74s\n",
      "703:\ttotal: 16s\tremaining: 6.71s\n",
      "704:\ttotal: 16s\tremaining: 6.69s\n",
      "705:\ttotal: 16s\tremaining: 6.67s\n",
      "706:\ttotal: 16s\tremaining: 6.65s\n",
      "707:\ttotal: 16.1s\tremaining: 6.62s\n",
      "708:\ttotal: 16.1s\tremaining: 6.6s\n",
      "709:\ttotal: 16.1s\tremaining: 6.58s\n",
      "710:\ttotal: 16.1s\tremaining: 6.55s\n",
      "711:\ttotal: 16.1s\tremaining: 6.53s\n",
      "712:\ttotal: 16.2s\tremaining: 6.51s\n",
      "713:\ttotal: 16.2s\tremaining: 6.49s\n",
      "714:\ttotal: 16.2s\tremaining: 6.46s\n",
      "715:\ttotal: 16.2s\tremaining: 6.44s\n",
      "716:\ttotal: 16.3s\tremaining: 6.42s\n",
      "717:\ttotal: 16.3s\tremaining: 6.39s\n",
      "718:\ttotal: 16.3s\tremaining: 6.37s\n",
      "719:\ttotal: 16.3s\tremaining: 6.35s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720:\ttotal: 16.3s\tremaining: 6.33s\n",
      "721:\ttotal: 16.4s\tremaining: 6.3s\n",
      "722:\ttotal: 16.4s\tremaining: 6.28s\n",
      "723:\ttotal: 16.4s\tremaining: 6.26s\n",
      "724:\ttotal: 16.4s\tremaining: 6.24s\n",
      "725:\ttotal: 16.5s\tremaining: 6.21s\n",
      "726:\ttotal: 16.5s\tremaining: 6.19s\n",
      "727:\ttotal: 16.5s\tremaining: 6.17s\n",
      "728:\ttotal: 16.5s\tremaining: 6.14s\n",
      "729:\ttotal: 16.5s\tremaining: 6.12s\n",
      "730:\ttotal: 16.6s\tremaining: 6.1s\n",
      "731:\ttotal: 16.6s\tremaining: 6.08s\n",
      "732:\ttotal: 16.6s\tremaining: 6.05s\n",
      "733:\ttotal: 16.6s\tremaining: 6.03s\n",
      "734:\ttotal: 16.7s\tremaining: 6s\n",
      "735:\ttotal: 16.7s\tremaining: 5.98s\n",
      "736:\ttotal: 16.7s\tremaining: 5.96s\n",
      "737:\ttotal: 16.7s\tremaining: 5.93s\n",
      "738:\ttotal: 16.7s\tremaining: 5.91s\n",
      "739:\ttotal: 16.8s\tremaining: 5.89s\n",
      "740:\ttotal: 16.8s\tremaining: 5.87s\n",
      "741:\ttotal: 16.8s\tremaining: 5.84s\n",
      "742:\ttotal: 16.8s\tremaining: 5.82s\n",
      "743:\ttotal: 16.9s\tremaining: 5.8s\n",
      "744:\ttotal: 16.9s\tremaining: 5.78s\n",
      "745:\ttotal: 16.9s\tremaining: 5.75s\n",
      "746:\ttotal: 16.9s\tremaining: 5.73s\n",
      "747:\ttotal: 16.9s\tremaining: 5.71s\n",
      "748:\ttotal: 17s\tremaining: 5.68s\n",
      "749:\ttotal: 17s\tremaining: 5.66s\n",
      "750:\ttotal: 17s\tremaining: 5.64s\n",
      "751:\ttotal: 17s\tremaining: 5.62s\n",
      "752:\ttotal: 17.1s\tremaining: 5.59s\n",
      "753:\ttotal: 17.1s\tremaining: 5.57s\n",
      "754:\ttotal: 17.1s\tremaining: 5.55s\n",
      "755:\ttotal: 17.1s\tremaining: 5.53s\n",
      "756:\ttotal: 17.1s\tremaining: 5.5s\n",
      "757:\ttotal: 17.2s\tremaining: 5.48s\n",
      "758:\ttotal: 17.2s\tremaining: 5.46s\n",
      "759:\ttotal: 17.2s\tremaining: 5.44s\n",
      "760:\ttotal: 17.2s\tremaining: 5.41s\n",
      "761:\ttotal: 17.3s\tremaining: 5.39s\n",
      "762:\ttotal: 17.3s\tremaining: 5.37s\n",
      "763:\ttotal: 17.3s\tremaining: 5.35s\n",
      "764:\ttotal: 17.3s\tremaining: 5.32s\n",
      "765:\ttotal: 17.4s\tremaining: 5.3s\n",
      "766:\ttotal: 17.4s\tremaining: 5.28s\n",
      "767:\ttotal: 17.4s\tremaining: 5.26s\n",
      "768:\ttotal: 17.4s\tremaining: 5.23s\n",
      "769:\ttotal: 17.4s\tremaining: 5.21s\n",
      "770:\ttotal: 17.5s\tremaining: 5.19s\n",
      "771:\ttotal: 17.5s\tremaining: 5.17s\n",
      "772:\ttotal: 17.5s\tremaining: 5.14s\n",
      "773:\ttotal: 17.5s\tremaining: 5.12s\n",
      "774:\ttotal: 17.6s\tremaining: 5.1s\n",
      "775:\ttotal: 17.6s\tremaining: 5.08s\n",
      "776:\ttotal: 17.6s\tremaining: 5.05s\n",
      "777:\ttotal: 17.6s\tremaining: 5.03s\n",
      "778:\ttotal: 17.6s\tremaining: 5.01s\n",
      "779:\ttotal: 17.7s\tremaining: 4.98s\n",
      "780:\ttotal: 17.7s\tremaining: 4.96s\n",
      "781:\ttotal: 17.7s\tremaining: 4.94s\n",
      "782:\ttotal: 17.7s\tremaining: 4.92s\n",
      "783:\ttotal: 17.8s\tremaining: 4.89s\n",
      "784:\ttotal: 17.8s\tremaining: 4.87s\n",
      "785:\ttotal: 17.8s\tremaining: 4.85s\n",
      "786:\ttotal: 17.8s\tremaining: 4.83s\n",
      "787:\ttotal: 17.9s\tremaining: 4.8s\n",
      "788:\ttotal: 17.9s\tremaining: 4.78s\n",
      "789:\ttotal: 17.9s\tremaining: 4.76s\n",
      "790:\ttotal: 17.9s\tremaining: 4.74s\n",
      "791:\ttotal: 17.9s\tremaining: 4.71s\n",
      "792:\ttotal: 18s\tremaining: 4.69s\n",
      "793:\ttotal: 18s\tremaining: 4.67s\n",
      "794:\ttotal: 18s\tremaining: 4.64s\n",
      "795:\ttotal: 18s\tremaining: 4.62s\n",
      "796:\ttotal: 18.1s\tremaining: 4.6s\n",
      "797:\ttotal: 18.1s\tremaining: 4.58s\n",
      "798:\ttotal: 18.1s\tremaining: 4.55s\n",
      "799:\ttotal: 18.1s\tremaining: 4.53s\n",
      "800:\ttotal: 18.1s\tremaining: 4.5s\n",
      "801:\ttotal: 18.2s\tremaining: 4.48s\n",
      "802:\ttotal: 18.2s\tremaining: 4.46s\n",
      "803:\ttotal: 18.2s\tremaining: 4.44s\n",
      "804:\ttotal: 18.2s\tremaining: 4.42s\n",
      "805:\ttotal: 18.3s\tremaining: 4.39s\n",
      "806:\ttotal: 18.3s\tremaining: 4.37s\n",
      "807:\ttotal: 18.3s\tremaining: 4.35s\n",
      "808:\ttotal: 18.3s\tremaining: 4.33s\n",
      "809:\ttotal: 18.3s\tremaining: 4.3s\n",
      "810:\ttotal: 18.4s\tremaining: 4.28s\n",
      "811:\ttotal: 18.4s\tremaining: 4.26s\n",
      "812:\ttotal: 18.4s\tremaining: 4.23s\n",
      "813:\ttotal: 18.4s\tremaining: 4.21s\n",
      "814:\ttotal: 18.5s\tremaining: 4.19s\n",
      "815:\ttotal: 18.5s\tremaining: 4.17s\n",
      "816:\ttotal: 18.5s\tremaining: 4.14s\n",
      "817:\ttotal: 18.5s\tremaining: 4.12s\n",
      "818:\ttotal: 18.5s\tremaining: 4.1s\n",
      "819:\ttotal: 18.6s\tremaining: 4.08s\n",
      "820:\ttotal: 18.6s\tremaining: 4.05s\n",
      "821:\ttotal: 18.6s\tremaining: 4.03s\n",
      "822:\ttotal: 18.6s\tremaining: 4.01s\n",
      "823:\ttotal: 18.7s\tremaining: 3.98s\n",
      "824:\ttotal: 18.7s\tremaining: 3.96s\n",
      "825:\ttotal: 18.7s\tremaining: 3.94s\n",
      "826:\ttotal: 18.7s\tremaining: 3.92s\n",
      "827:\ttotal: 18.7s\tremaining: 3.89s\n",
      "828:\ttotal: 18.8s\tremaining: 3.87s\n",
      "829:\ttotal: 18.8s\tremaining: 3.85s\n",
      "830:\ttotal: 18.8s\tremaining: 3.83s\n",
      "831:\ttotal: 18.8s\tremaining: 3.8s\n",
      "832:\ttotal: 18.9s\tremaining: 3.78s\n",
      "833:\ttotal: 18.9s\tremaining: 3.76s\n",
      "834:\ttotal: 18.9s\tremaining: 3.73s\n",
      "835:\ttotal: 18.9s\tremaining: 3.71s\n",
      "836:\ttotal: 18.9s\tremaining: 3.69s\n",
      "837:\ttotal: 19s\tremaining: 3.67s\n",
      "838:\ttotal: 19s\tremaining: 3.64s\n",
      "839:\ttotal: 19s\tremaining: 3.62s\n",
      "840:\ttotal: 19s\tremaining: 3.6s\n",
      "841:\ttotal: 19.1s\tremaining: 3.58s\n",
      "842:\ttotal: 19.1s\tremaining: 3.55s\n",
      "843:\ttotal: 19.1s\tremaining: 3.53s\n",
      "844:\ttotal: 19.1s\tremaining: 3.51s\n",
      "845:\ttotal: 19.1s\tremaining: 3.48s\n",
      "846:\ttotal: 19.2s\tremaining: 3.46s\n",
      "847:\ttotal: 19.2s\tremaining: 3.44s\n",
      "848:\ttotal: 19.2s\tremaining: 3.42s\n",
      "849:\ttotal: 19.2s\tremaining: 3.39s\n",
      "850:\ttotal: 19.2s\tremaining: 3.37s\n",
      "851:\ttotal: 19.3s\tremaining: 3.35s\n",
      "852:\ttotal: 19.3s\tremaining: 3.33s\n",
      "853:\ttotal: 19.3s\tremaining: 3.3s\n",
      "854:\ttotal: 19.3s\tremaining: 3.28s\n",
      "855:\ttotal: 19.4s\tremaining: 3.26s\n",
      "856:\ttotal: 19.4s\tremaining: 3.23s\n",
      "857:\ttotal: 19.4s\tremaining: 3.21s\n",
      "858:\ttotal: 19.4s\tremaining: 3.19s\n",
      "859:\ttotal: 19.5s\tremaining: 3.17s\n",
      "860:\ttotal: 19.5s\tremaining: 3.14s\n",
      "861:\ttotal: 19.5s\tremaining: 3.12s\n",
      "862:\ttotal: 19.5s\tremaining: 3.1s\n",
      "863:\ttotal: 19.5s\tremaining: 3.08s\n",
      "864:\ttotal: 19.6s\tremaining: 3.05s\n",
      "865:\ttotal: 19.6s\tremaining: 3.03s\n",
      "866:\ttotal: 19.6s\tremaining: 3.01s\n",
      "867:\ttotal: 19.6s\tremaining: 2.98s\n",
      "868:\ttotal: 19.7s\tremaining: 2.96s\n",
      "869:\ttotal: 19.7s\tremaining: 2.94s\n",
      "870:\ttotal: 19.7s\tremaining: 2.92s\n",
      "871:\ttotal: 19.7s\tremaining: 2.9s\n",
      "872:\ttotal: 19.7s\tremaining: 2.87s\n",
      "873:\ttotal: 19.8s\tremaining: 2.85s\n",
      "874:\ttotal: 19.8s\tremaining: 2.83s\n",
      "875:\ttotal: 19.8s\tremaining: 2.8s\n",
      "876:\ttotal: 19.8s\tremaining: 2.78s\n",
      "877:\ttotal: 19.9s\tremaining: 2.76s\n",
      "878:\ttotal: 19.9s\tremaining: 2.74s\n",
      "879:\ttotal: 19.9s\tremaining: 2.71s\n",
      "880:\ttotal: 19.9s\tremaining: 2.69s\n",
      "881:\ttotal: 19.9s\tremaining: 2.67s\n",
      "882:\ttotal: 20s\tremaining: 2.65s\n",
      "883:\ttotal: 20s\tremaining: 2.62s\n",
      "884:\ttotal: 20s\tremaining: 2.6s\n",
      "885:\ttotal: 20s\tremaining: 2.58s\n",
      "886:\ttotal: 20.1s\tremaining: 2.56s\n",
      "887:\ttotal: 20.1s\tremaining: 2.53s\n",
      "888:\ttotal: 20.1s\tremaining: 2.51s\n",
      "889:\ttotal: 20.1s\tremaining: 2.49s\n",
      "890:\ttotal: 20.1s\tremaining: 2.46s\n",
      "891:\ttotal: 20.2s\tremaining: 2.44s\n",
      "892:\ttotal: 20.2s\tremaining: 2.42s\n",
      "893:\ttotal: 20.2s\tremaining: 2.4s\n",
      "894:\ttotal: 20.2s\tremaining: 2.37s\n",
      "895:\ttotal: 20.3s\tremaining: 2.35s\n",
      "896:\ttotal: 20.3s\tremaining: 2.33s\n",
      "897:\ttotal: 20.3s\tremaining: 2.31s\n",
      "898:\ttotal: 20.3s\tremaining: 2.28s\n",
      "899:\ttotal: 20.4s\tremaining: 2.26s\n",
      "900:\ttotal: 20.4s\tremaining: 2.24s\n",
      "901:\ttotal: 20.4s\tremaining: 2.21s\n",
      "902:\ttotal: 20.4s\tremaining: 2.19s\n",
      "903:\ttotal: 20.4s\tremaining: 2.17s\n",
      "904:\ttotal: 20.5s\tremaining: 2.15s\n",
      "905:\ttotal: 20.5s\tremaining: 2.13s\n",
      "906:\ttotal: 20.5s\tremaining: 2.1s\n",
      "907:\ttotal: 20.5s\tremaining: 2.08s\n",
      "908:\ttotal: 20.6s\tremaining: 2.06s\n",
      "909:\ttotal: 20.6s\tremaining: 2.04s\n",
      "910:\ttotal: 20.6s\tremaining: 2.01s\n",
      "911:\ttotal: 20.6s\tremaining: 1.99s\n",
      "912:\ttotal: 20.6s\tremaining: 1.97s\n",
      "913:\ttotal: 20.7s\tremaining: 1.94s\n",
      "914:\ttotal: 20.7s\tremaining: 1.92s\n",
      "915:\ttotal: 20.7s\tremaining: 1.9s\n",
      "916:\ttotal: 20.7s\tremaining: 1.88s\n",
      "917:\ttotal: 20.8s\tremaining: 1.85s\n",
      "918:\ttotal: 20.8s\tremaining: 1.83s\n",
      "919:\ttotal: 20.8s\tremaining: 1.81s\n",
      "920:\ttotal: 20.8s\tremaining: 1.79s\n",
      "921:\ttotal: 20.9s\tremaining: 1.76s\n",
      "922:\ttotal: 20.9s\tremaining: 1.74s\n",
      "923:\ttotal: 20.9s\tremaining: 1.72s\n",
      "924:\ttotal: 20.9s\tremaining: 1.7s\n",
      "925:\ttotal: 20.9s\tremaining: 1.67s\n",
      "926:\ttotal: 21s\tremaining: 1.65s\n",
      "927:\ttotal: 21s\tremaining: 1.63s\n",
      "928:\ttotal: 21s\tremaining: 1.61s\n",
      "929:\ttotal: 21s\tremaining: 1.58s\n",
      "930:\ttotal: 21.1s\tremaining: 1.56s\n",
      "931:\ttotal: 21.1s\tremaining: 1.54s\n",
      "932:\ttotal: 21.1s\tremaining: 1.51s\n",
      "933:\ttotal: 21.1s\tremaining: 1.49s\n",
      "934:\ttotal: 21.1s\tremaining: 1.47s\n",
      "935:\ttotal: 21.2s\tremaining: 1.45s\n",
      "936:\ttotal: 21.2s\tremaining: 1.42s\n",
      "937:\ttotal: 21.2s\tremaining: 1.4s\n",
      "938:\ttotal: 21.2s\tremaining: 1.38s\n",
      "939:\ttotal: 21.3s\tremaining: 1.36s\n",
      "940:\ttotal: 21.3s\tremaining: 1.33s\n",
      "941:\ttotal: 21.3s\tremaining: 1.31s\n",
      "942:\ttotal: 21.3s\tremaining: 1.29s\n",
      "943:\ttotal: 21.4s\tremaining: 1.27s\n",
      "944:\ttotal: 21.4s\tremaining: 1.24s\n",
      "945:\ttotal: 21.4s\tremaining: 1.22s\n",
      "946:\ttotal: 21.4s\tremaining: 1.2s\n",
      "947:\ttotal: 21.4s\tremaining: 1.18s\n",
      "948:\ttotal: 21.5s\tremaining: 1.15s\n",
      "949:\ttotal: 21.5s\tremaining: 1.13s\n",
      "950:\ttotal: 21.5s\tremaining: 1.11s\n",
      "951:\ttotal: 21.5s\tremaining: 1.08s\n",
      "952:\ttotal: 21.6s\tremaining: 1.06s\n",
      "953:\ttotal: 21.6s\tremaining: 1.04s\n",
      "954:\ttotal: 21.6s\tremaining: 1.02s\n",
      "955:\ttotal: 21.6s\tremaining: 995ms\n",
      "956:\ttotal: 21.6s\tremaining: 972ms\n",
      "957:\ttotal: 21.7s\tremaining: 950ms\n",
      "958:\ttotal: 21.7s\tremaining: 927ms\n",
      "959:\ttotal: 21.7s\tremaining: 905ms\n",
      "960:\ttotal: 21.7s\tremaining: 882ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "961:\ttotal: 21.8s\tremaining: 859ms\n",
      "962:\ttotal: 21.8s\tremaining: 837ms\n",
      "963:\ttotal: 21.8s\tremaining: 814ms\n",
      "964:\ttotal: 21.8s\tremaining: 792ms\n",
      "965:\ttotal: 21.8s\tremaining: 769ms\n",
      "966:\ttotal: 21.9s\tremaining: 746ms\n",
      "967:\ttotal: 21.9s\tremaining: 724ms\n",
      "968:\ttotal: 21.9s\tremaining: 701ms\n",
      "969:\ttotal: 21.9s\tremaining: 678ms\n",
      "970:\ttotal: 22s\tremaining: 656ms\n",
      "971:\ttotal: 22s\tremaining: 633ms\n",
      "972:\ttotal: 22s\tremaining: 611ms\n",
      "973:\ttotal: 22s\tremaining: 588ms\n",
      "974:\ttotal: 22s\tremaining: 565ms\n",
      "975:\ttotal: 22.1s\tremaining: 543ms\n",
      "976:\ttotal: 22.1s\tremaining: 520ms\n",
      "977:\ttotal: 22.1s\tremaining: 497ms\n",
      "978:\ttotal: 22.1s\tremaining: 475ms\n",
      "979:\ttotal: 22.2s\tremaining: 452ms\n",
      "980:\ttotal: 22.2s\tremaining: 430ms\n",
      "981:\ttotal: 22.2s\tremaining: 407ms\n",
      "982:\ttotal: 22.2s\tremaining: 384ms\n",
      "983:\ttotal: 22.2s\tremaining: 362ms\n",
      "984:\ttotal: 22.3s\tremaining: 339ms\n",
      "985:\ttotal: 22.3s\tremaining: 317ms\n",
      "986:\ttotal: 22.3s\tremaining: 294ms\n",
      "987:\ttotal: 22.3s\tremaining: 271ms\n",
      "988:\ttotal: 22.4s\tremaining: 249ms\n",
      "989:\ttotal: 22.4s\tremaining: 226ms\n",
      "990:\ttotal: 22.4s\tremaining: 204ms\n",
      "991:\ttotal: 22.4s\tremaining: 181ms\n",
      "992:\ttotal: 22.5s\tremaining: 158ms\n",
      "993:\ttotal: 22.5s\tremaining: 136ms\n",
      "994:\ttotal: 22.5s\tremaining: 113ms\n",
      "995:\ttotal: 22.5s\tremaining: 90.4ms\n",
      "996:\ttotal: 22.5s\tremaining: 67.8ms\n",
      "997:\ttotal: 22.6s\tremaining: 45.2ms\n",
      "998:\ttotal: 22.6s\tremaining: 22.6ms\n",
      "999:\ttotal: 22.6s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(pd.DataFrame(ed_texts_df[cols]), \n",
    "                                                    ed_texts_df['label'], \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=ed_texts_df['label'])\n",
    "\n",
    "learner = ActiveLearner(\n",
    "                        estimator=CatBoostClassifier(\n",
    "                        cat_features=['first_word', 'last_word'],\n",
    "                        text_features=['line'],\n",
    "                        loss_function='Logloss',\n",
    "                        eval_metric='AUC',\n",
    "                        task_type='CPU',\n",
    "                        text_processing = {\n",
    "                            \"tokenizers\" : [{\n",
    "                                \"tokenizer_id\" : \"Space\",\n",
    "                                \"separator_type\" : \"ByDelimiter\",\n",
    "                                \"delimiter\" : \" \"\n",
    "                            }],\n",
    "\n",
    "                            \"dictionaries\" : [{\n",
    "                                \"dictionary_id\" : \"BiGram\",\n",
    "                                \"token_level_type\": \"Letter\",\n",
    "                                \"max_dictionary_size\" : \"50000\",\n",
    "                                \"occurrence_lower_bound\" : \"1\",\n",
    "                                \"gram_order\" : \"2\"\n",
    "                            },\n",
    "                            {\n",
    "                                \"dictionary_id\" : \"UniGram\",\n",
    "                                \"token_level_type\": \"Letter\",\n",
    "                                \"max_dictionary_size\" : \"50000\",\n",
    "                                \"occurrence_lower_bound\" : \"3\",\n",
    "                                \"gram_order\" : \"1\"\n",
    "                            }\n",
    "                            ],\n",
    "\n",
    "                            \"feature_processing\" : {\n",
    "                                \"default\" : [\n",
    "                                        {\n",
    "                                        \"dictionaries_names\" : [\"UniGram\", \"BiGram\"],\n",
    "                                        \"feature_calcers\" : [\"BoW\"],\n",
    "                                        \"tokenizers_names\" : [\"Space\"]\n",
    "                                    },\n",
    "                                        {\n",
    "                                    \"dictionaries_names\" : [\"UniGram\", \"BiGram\"],\n",
    "                                    \"feature_calcers\" : [\"NaiveBayes\"],\n",
    "                                    \"tokenizers_names\" : [\"Space\"]\n",
    "                                },{\n",
    "                                    \"dictionaries_names\" : [\"UniGram\", \"BiGram\"],\n",
    "                                    \"feature_calcers\" : [\"BM25\"],\n",
    "                                    \"tokenizers_names\" : [\"Space\"]\n",
    "                                },\n",
    "                                ],\n",
    "                            }\n",
    "                        }\n",
    "                    ),\n",
    "    X_training=x_train, y_training=y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = learner.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "f1_scores = []\n",
    "\n",
    "for treshold in tresholds:\n",
    "    y_probs = learner.predict_proba(x_test)\n",
    "    y_preds = np.where(y_probs[:, 1] > treshold, 1, 0)\n",
    "    accuracies.append((treshold, accuracy_score(y_preds, y_test)))\n",
    "    f1_scores.append((treshold, f1_score(y_preds, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1, 0.5739502820137874),\n",
       " (0.2, 0.6494673072905787),\n",
       " (0.3, 0.7150616252350115),\n",
       " (0.4, 0.749321077919365),\n",
       " (0.5, 0.7702109880927512),\n",
       " (0.6, 0.7622728222268644),\n",
       " (0.7, 0.732504700229789),\n",
       " (0.8, 0.6685815750992271),\n",
       " (0.9, 0.5809484019218717)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1, 0.696976450486591),\n",
       " (0.2, 0.7318632150846917),\n",
       " (0.3, 0.7633587786259541),\n",
       " (0.4, 0.7730281823340269),\n",
       " (0.5, 0.7710241465445462),\n",
       " (0.6, 0.736207695873899),\n",
       " (0.7, 0.664922150987832),\n",
       " (0.8, 0.5159420289855072),\n",
       " (0.9, 0.26895043731778423)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.64      0.72      4849\n",
      "           1       0.70      0.86      0.77      4725\n",
      "\n",
      "    accuracy                           0.75      9574\n",
      "   macro avg       0.76      0.75      0.75      9574\n",
      "weighted avg       0.76      0.75      0.75      9574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_probs = learner.predict_proba(x_test)\n",
    "y_preds = np.where(y_probs[:, 1] > 0.4, 1, 0)\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.64      0.72      4849\n",
      "           1       0.70      0.86      0.77      4725\n",
      "\n",
      "    accuracy                           0.75      9574\n",
      "   macro avg       0.76      0.75      0.75      9574\n",
      "weighted avg       0.76      0.75      0.75      9574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_probs = learner.predict_proba(x_test)\n",
    "y_preds = np.where(y_probs[:, 1] > 0.4, 1, 0)\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(learner.estimator, x_test, y_test)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f9b3c104a50>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "CatBoostClassifier.save_model(learner.estimator, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11286/580191101.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/venv/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1968\u001b[0m     \"\"\"\n\u001b[1;32m   1969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1970\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 93\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11286/3002783055.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mholdout_ed_texts_df_0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mquery_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_inst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/venv/lib/python3.7/site-packages/modAL/models/learners.py\u001b[0m in \u001b[0;36mteach\u001b[0;34m(self, X, y, bootstrap, only_new, **fit_kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mKeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfit\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0monly_new\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_to_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/venv/lib/python3.7/site-packages/modAL/models/base.py\u001b[0m in \u001b[0;36m_add_training_data\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_vstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_vstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/venv/lib/python3.7/site-packages/modAL/utils/data.py\u001b[0m in \u001b[0;36mdata_vstack\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/venv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   8963\u001b[0m                 \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8964\u001b[0m                 \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8965\u001b[0;31m                 \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8966\u001b[0m             )\n\u001b[1;32m   8967\u001b[0m         ).__finalize__(self, method=\"append\")\n",
      "\u001b[0;32m~/code/venv/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/venv/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/venv/lib/python3.7/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;34m\"only Series and DataFrame objs are valid\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 )\n\u001b[0;32m--> 384\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0mndims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "x_pool = holdout_ed_texts_df_0[cols]\n",
    "query_idx, query_inst = learner.query(x_pool, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>len_line</th>\n",
       "      <th>first_word</th>\n",
       "      <th>last_word</th>\n",
       "      <th>count_decimal</th>\n",
       "      <th>count_uppercased_chars</th>\n",
       "      <th>count_stopwords</th>\n",
       "      <th>count_puncts</th>\n",
       "      <th>gram_подтверждающего_flg</th>\n",
       "      <th>gram_составляющих_flg</th>\n",
       "      <th>...</th>\n",
       "      <th>gram_мероприятия_flg</th>\n",
       "      <th>gram_окружающей_среды_flg</th>\n",
       "      <th>gram_органам_органам_flg</th>\n",
       "      <th>gram_суд_flg</th>\n",
       "      <th>gram_земельный_участок_flg</th>\n",
       "      <th>gram_приобретение_flg</th>\n",
       "      <th>gram_состоянию_flg</th>\n",
       "      <th>gram_предложение_flg</th>\n",
       "      <th>gram_края_flg</th>\n",
       "      <th>gram_подлежит_рассмотрению_flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1610772</th>\n",
       "      <td>Обязательными условиями пребывания в маломестн...</td>\n",
       "      <td>73</td>\n",
       "      <td>обязательными</td>\n",
       "      <td>являются:</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23578</th>\n",
       "      <td>Председатель  Комиссии - председатель Государс...</td>\n",
       "      <td>97</td>\n",
       "      <td>председатель</td>\n",
       "      <td>крым;</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451924</th>\n",
       "      <td>72. Юридические лица, их руководители, иные до...</td>\n",
       "      <td>500</td>\n",
       "      <td>72.</td>\n",
       "      <td>федерации.</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229600</th>\n",
       "      <td>Структурное подразделение Департамента, осущес...</td>\n",
       "      <td>166</td>\n",
       "      <td>структурное</td>\n",
       "      <td>комитет).</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327985</th>\n",
       "      <td>8. При осуществлении лицензионного контроля до...</td>\n",
       "      <td>81</td>\n",
       "      <td>8.</td>\n",
       "      <td>вправе:</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400635</th>\n",
       "      <td>2) проведение социально-реабилитационных мероп...</td>\n",
       "      <td>86</td>\n",
       "      <td>2)</td>\n",
       "      <td>обслуживания:</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183862</th>\n",
       "      <td>3. Выплата предоставляется в размере 10000 руб...</td>\n",
       "      <td>50</td>\n",
       "      <td>3.</td>\n",
       "      <td>рублей.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342949</th>\n",
       "      <td>в соответствии с подпунктом 77 части 1 статьи ...</td>\n",
       "      <td>194</td>\n",
       "      <td>в</td>\n",
       "      <td>рублей.</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863023</th>\n",
       "      <td>3.24. Основанием для начала административной п...</td>\n",
       "      <td>126</td>\n",
       "      <td>3.24.</td>\n",
       "      <td>субсидии.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176678</th>\n",
       "      <td>Специалист 1-й категории отдела потребительско...</td>\n",
       "      <td>54</td>\n",
       "      <td>специалист</td>\n",
       "      <td>рынка</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      line  len_line  \\\n",
       "1610772  Обязательными условиями пребывания в маломестн...        73   \n",
       "23578    Председатель  Комиссии - председатель Государс...        97   \n",
       "1451924  72. Юридические лица, их руководители, иные до...       500   \n",
       "229600   Структурное подразделение Департамента, осущес...       166   \n",
       "327985   8. При осуществлении лицензионного контроля до...        81   \n",
       "...                                                    ...       ...   \n",
       "400635   2) проведение социально-реабилитационных мероп...        86   \n",
       "183862   3. Выплата предоставляется в размере 10000 руб...        50   \n",
       "342949   в соответствии с подпунктом 77 части 1 статьи ...       194   \n",
       "863023   3.24. Основанием для начала административной п...       126   \n",
       "1176678  Специалист 1-й категории отдела потребительско...        54   \n",
       "\n",
       "            first_word      last_word  count_decimal  count_uppercased_chars  \\\n",
       "1610772  обязательными      являются:              0                       1   \n",
       "23578     председатель          крым;              0                       5   \n",
       "1451924            72.     федерации.              1                       3   \n",
       "229600     структурное      комитет).              0                       4   \n",
       "327985              8.        вправе:              1                       2   \n",
       "...                ...            ...            ...                     ...   \n",
       "400635              2)  обслуживания:              1                       0   \n",
       "183862              3.        рублей.              2                       1   \n",
       "342949               в        рублей.              5                       3   \n",
       "863023           3.24.      субсидии.              2                       1   \n",
       "1176678     специалист          рынка              1                       1   \n",
       "\n",
       "         count_stopwords  count_puncts  gram_подтверждающего_flg  \\\n",
       "1610772                1            74                         0   \n",
       "23578                  1            98                         0   \n",
       "1451924               10           501                         0   \n",
       "229600                 2           166                         0   \n",
       "327985                 1            82                         0   \n",
       "...                  ...           ...                       ...   \n",
       "400635                 1            87                         0   \n",
       "183862                 1            51                         0   \n",
       "342949                 3           195                         1   \n",
       "863023                 2           127                         0   \n",
       "1176678                0            55                         0   \n",
       "\n",
       "         gram_составляющих_flg  ...  gram_мероприятия_flg  \\\n",
       "1610772                      0  ...                     0   \n",
       "23578                        0  ...                     0   \n",
       "1451924                      0  ...                     0   \n",
       "229600                       0  ...                     0   \n",
       "327985                       0  ...                     0   \n",
       "...                        ...  ...                   ...   \n",
       "400635                       0  ...                     0   \n",
       "183862                       0  ...                     0   \n",
       "342949                       0  ...                     0   \n",
       "863023                       0  ...                     0   \n",
       "1176678                      0  ...                     0   \n",
       "\n",
       "         gram_окружающей_среды_flg  gram_органам_органам_flg  gram_суд_flg  \\\n",
       "1610772                          0                         0             0   \n",
       "23578                            0                         0             1   \n",
       "1451924                          0                         0             1   \n",
       "229600                           0                         0             1   \n",
       "327985                           0                         0             0   \n",
       "...                            ...                       ...           ...   \n",
       "400635                           0                         0             0   \n",
       "183862                           0                         0             0   \n",
       "342949                           0                         0             1   \n",
       "863023                           0                         0             0   \n",
       "1176678                          0                         0             0   \n",
       "\n",
       "         gram_земельный_участок_flg  gram_приобретение_flg  \\\n",
       "1610772                           0                      0   \n",
       "23578                             0                      0   \n",
       "1451924                           0                      0   \n",
       "229600                            0                      0   \n",
       "327985                            0                      0   \n",
       "...                             ...                    ...   \n",
       "400635                            0                      0   \n",
       "183862                            0                      0   \n",
       "342949                            0                      0   \n",
       "863023                            0                      0   \n",
       "1176678                           0                      0   \n",
       "\n",
       "         gram_состоянию_flg  gram_предложение_flg  gram_края_flg  \\\n",
       "1610772                   0                     0              0   \n",
       "23578                     0                     0              0   \n",
       "1451924                   0                     0              0   \n",
       "229600                    0                     0              0   \n",
       "327985                    0                     0              0   \n",
       "...                     ...                   ...            ...   \n",
       "400635                    0                     0              0   \n",
       "183862                    0                     0              0   \n",
       "342949                    0                     0              0   \n",
       "863023                    0                     0              0   \n",
       "1176678                   0                     0              0   \n",
       "\n",
       "         gram_подлежит_рассмотрению_flg  \n",
       "1610772                               0  \n",
       "23578                                 0  \n",
       "1451924                               0  \n",
       "229600                                0  \n",
       "327985                                0  \n",
       "...                                 ...  \n",
       "400635                                0  \n",
       "183862                                0  \n",
       "342949                                0  \n",
       "863023                                0  \n",
       "1176678                               0  \n",
       "\n",
       "[1000 rows x 126 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pool.iloc[query_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<class 'pandas.core.series.Series'> datatype is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11286/3860010644.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/venv/lib/python3.7/site-packages/modAL/models/learners.py\u001b[0m in \u001b[0;36mteach\u001b[0;34m(self, X, y, bootstrap, only_new, **fit_kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mKeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfit\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0monly_new\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_to_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/venv/lib/python3.7/site-packages/modAL/models/base.py\u001b[0m in \u001b[0;36m_add_training_data\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_vstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_vstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 raise ValueError('the dimensions of the new training data and label must'\n",
      "\u001b[0;32m~/code/venv/lib/python3.7/site-packages/modAL/utils/data.py\u001b[0m in \u001b[0;36mdata_vstack\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s datatype is not supported'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: <class 'pandas.core.series.Series'> datatype is not supported"
     ]
    }
   ],
   "source": [
    "learner.teach(x_pool.iloc[query_idx], [0 for _ in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.055615\n",
      "0:\ttotal: 36.5ms\tremaining: 36.5s\n",
      "1:\ttotal: 66.2ms\tremaining: 33s\n",
      "2:\ttotal: 98.5ms\tremaining: 32.7s\n",
      "3:\ttotal: 127ms\tremaining: 31.7s\n",
      "4:\ttotal: 154ms\tremaining: 30.7s\n",
      "5:\ttotal: 187ms\tremaining: 31s\n",
      "6:\ttotal: 220ms\tremaining: 31.2s\n",
      "7:\ttotal: 249ms\tremaining: 30.8s\n",
      "8:\ttotal: 278ms\tremaining: 30.6s\n",
      "9:\ttotal: 306ms\tremaining: 30.3s\n",
      "10:\ttotal: 336ms\tremaining: 30.2s\n",
      "11:\ttotal: 366ms\tremaining: 30.1s\n",
      "12:\ttotal: 394ms\tremaining: 29.9s\n",
      "13:\ttotal: 425ms\tremaining: 29.9s\n",
      "14:\ttotal: 458ms\tremaining: 30.1s\n",
      "15:\ttotal: 487ms\tremaining: 30s\n",
      "16:\ttotal: 519ms\tremaining: 30s\n",
      "17:\ttotal: 550ms\tremaining: 30s\n",
      "18:\ttotal: 579ms\tremaining: 29.9s\n",
      "19:\ttotal: 608ms\tremaining: 29.8s\n",
      "20:\ttotal: 637ms\tremaining: 29.7s\n",
      "21:\ttotal: 667ms\tremaining: 29.7s\n",
      "22:\ttotal: 697ms\tremaining: 29.6s\n",
      "23:\ttotal: 725ms\tremaining: 29.5s\n",
      "24:\ttotal: 756ms\tremaining: 29.5s\n",
      "25:\ttotal: 784ms\tremaining: 29.4s\n",
      "26:\ttotal: 816ms\tremaining: 29.4s\n",
      "27:\ttotal: 845ms\tremaining: 29.3s\n",
      "28:\ttotal: 875ms\tremaining: 29.3s\n",
      "29:\ttotal: 904ms\tremaining: 29.2s\n",
      "30:\ttotal: 935ms\tremaining: 29.2s\n",
      "31:\ttotal: 963ms\tremaining: 29.1s\n",
      "32:\ttotal: 991ms\tremaining: 29s\n",
      "33:\ttotal: 1.02s\tremaining: 29s\n",
      "34:\ttotal: 1.05s\tremaining: 29s\n",
      "35:\ttotal: 1.08s\tremaining: 29s\n",
      "36:\ttotal: 1.11s\tremaining: 28.9s\n",
      "37:\ttotal: 1.14s\tremaining: 28.8s\n",
      "38:\ttotal: 1.17s\tremaining: 28.8s\n",
      "39:\ttotal: 1.2s\tremaining: 28.7s\n",
      "40:\ttotal: 1.23s\tremaining: 28.7s\n",
      "41:\ttotal: 1.25s\tremaining: 28.6s\n",
      "42:\ttotal: 1.29s\tremaining: 28.6s\n",
      "43:\ttotal: 1.32s\tremaining: 28.6s\n",
      "44:\ttotal: 1.34s\tremaining: 28.6s\n",
      "45:\ttotal: 1.37s\tremaining: 28.5s\n",
      "46:\ttotal: 1.4s\tremaining: 28.4s\n",
      "47:\ttotal: 1.43s\tremaining: 28.3s\n",
      "48:\ttotal: 1.46s\tremaining: 28.2s\n",
      "49:\ttotal: 1.48s\tremaining: 28.2s\n",
      "50:\ttotal: 1.51s\tremaining: 28.2s\n",
      "51:\ttotal: 1.54s\tremaining: 28.2s\n",
      "52:\ttotal: 1.57s\tremaining: 28.1s\n",
      "53:\ttotal: 1.6s\tremaining: 28.1s\n",
      "54:\ttotal: 1.63s\tremaining: 28s\n",
      "55:\ttotal: 1.66s\tremaining: 28s\n",
      "56:\ttotal: 1.69s\tremaining: 27.9s\n",
      "57:\ttotal: 1.71s\tremaining: 27.8s\n",
      "58:\ttotal: 1.74s\tremaining: 27.8s\n",
      "59:\ttotal: 1.77s\tremaining: 27.7s\n",
      "60:\ttotal: 1.79s\tremaining: 27.6s\n",
      "61:\ttotal: 1.82s\tremaining: 27.6s\n",
      "62:\ttotal: 1.85s\tremaining: 27.6s\n",
      "63:\ttotal: 1.89s\tremaining: 27.6s\n",
      "64:\ttotal: 1.91s\tremaining: 27.5s\n",
      "65:\ttotal: 1.94s\tremaining: 27.5s\n",
      "66:\ttotal: 1.97s\tremaining: 27.4s\n",
      "67:\ttotal: 2s\tremaining: 27.4s\n",
      "68:\ttotal: 2.03s\tremaining: 27.4s\n",
      "69:\ttotal: 2.06s\tremaining: 27.3s\n",
      "70:\ttotal: 2.08s\tremaining: 27.2s\n",
      "71:\ttotal: 2.11s\tremaining: 27.2s\n",
      "72:\ttotal: 2.14s\tremaining: 27.2s\n",
      "73:\ttotal: 2.17s\tremaining: 27.1s\n",
      "74:\ttotal: 2.2s\tremaining: 27.1s\n",
      "75:\ttotal: 2.23s\tremaining: 27.1s\n",
      "76:\ttotal: 2.25s\tremaining: 27s\n",
      "77:\ttotal: 2.29s\tremaining: 27s\n",
      "78:\ttotal: 2.31s\tremaining: 27s\n",
      "79:\ttotal: 2.35s\tremaining: 27s\n",
      "80:\ttotal: 2.38s\tremaining: 26.9s\n",
      "81:\ttotal: 2.4s\tremaining: 26.9s\n",
      "82:\ttotal: 2.43s\tremaining: 26.9s\n",
      "83:\ttotal: 2.46s\tremaining: 26.8s\n",
      "84:\ttotal: 2.49s\tremaining: 26.8s\n",
      "85:\ttotal: 2.51s\tremaining: 26.7s\n",
      "86:\ttotal: 2.54s\tremaining: 26.7s\n",
      "87:\ttotal: 2.57s\tremaining: 26.6s\n",
      "88:\ttotal: 2.6s\tremaining: 26.6s\n",
      "89:\ttotal: 2.63s\tremaining: 26.6s\n",
      "90:\ttotal: 2.66s\tremaining: 26.5s\n",
      "91:\ttotal: 2.69s\tremaining: 26.5s\n",
      "92:\ttotal: 2.71s\tremaining: 26.5s\n",
      "93:\ttotal: 2.74s\tremaining: 26.4s\n",
      "94:\ttotal: 2.77s\tremaining: 26.4s\n",
      "95:\ttotal: 2.8s\tremaining: 26.4s\n",
      "96:\ttotal: 2.83s\tremaining: 26.4s\n",
      "97:\ttotal: 2.86s\tremaining: 26.3s\n",
      "98:\ttotal: 2.89s\tremaining: 26.3s\n",
      "99:\ttotal: 2.91s\tremaining: 26.2s\n",
      "100:\ttotal: 2.94s\tremaining: 26.2s\n",
      "101:\ttotal: 2.97s\tremaining: 26.2s\n",
      "102:\ttotal: 3s\tremaining: 26.1s\n",
      "103:\ttotal: 3.03s\tremaining: 26.1s\n",
      "104:\ttotal: 3.06s\tremaining: 26.1s\n",
      "105:\ttotal: 3.08s\tremaining: 26s\n",
      "106:\ttotal: 3.11s\tremaining: 26s\n",
      "107:\ttotal: 3.14s\tremaining: 25.9s\n",
      "108:\ttotal: 3.17s\tremaining: 25.9s\n",
      "109:\ttotal: 3.19s\tremaining: 25.9s\n",
      "110:\ttotal: 3.23s\tremaining: 25.8s\n",
      "111:\ttotal: 3.25s\tremaining: 25.8s\n",
      "112:\ttotal: 3.28s\tremaining: 25.8s\n",
      "113:\ttotal: 3.31s\tremaining: 25.7s\n",
      "114:\ttotal: 3.34s\tremaining: 25.7s\n",
      "115:\ttotal: 3.37s\tremaining: 25.6s\n",
      "116:\ttotal: 3.39s\tremaining: 25.6s\n",
      "117:\ttotal: 3.42s\tremaining: 25.6s\n",
      "118:\ttotal: 3.45s\tremaining: 25.6s\n",
      "119:\ttotal: 3.48s\tremaining: 25.5s\n",
      "120:\ttotal: 3.5s\tremaining: 25.5s\n",
      "121:\ttotal: 3.53s\tremaining: 25.4s\n",
      "122:\ttotal: 3.56s\tremaining: 25.4s\n",
      "123:\ttotal: 3.59s\tremaining: 25.4s\n",
      "124:\ttotal: 3.62s\tremaining: 25.3s\n",
      "125:\ttotal: 3.65s\tremaining: 25.3s\n",
      "126:\ttotal: 3.67s\tremaining: 25.2s\n",
      "127:\ttotal: 3.7s\tremaining: 25.2s\n",
      "128:\ttotal: 3.73s\tremaining: 25.2s\n",
      "129:\ttotal: 3.76s\tremaining: 25.2s\n",
      "130:\ttotal: 3.79s\tremaining: 25.1s\n",
      "131:\ttotal: 3.82s\tremaining: 25.1s\n",
      "132:\ttotal: 3.85s\tremaining: 25.1s\n",
      "133:\ttotal: 3.87s\tremaining: 25s\n",
      "134:\ttotal: 3.9s\tremaining: 25s\n",
      "135:\ttotal: 3.93s\tremaining: 24.9s\n",
      "136:\ttotal: 3.95s\tremaining: 24.9s\n",
      "137:\ttotal: 3.98s\tremaining: 24.9s\n",
      "138:\ttotal: 4.01s\tremaining: 24.8s\n",
      "139:\ttotal: 4.04s\tremaining: 24.8s\n",
      "140:\ttotal: 4.07s\tremaining: 24.8s\n",
      "141:\ttotal: 4.09s\tremaining: 24.7s\n",
      "142:\ttotal: 4.12s\tremaining: 24.7s\n",
      "143:\ttotal: 4.15s\tremaining: 24.7s\n",
      "144:\ttotal: 4.17s\tremaining: 24.6s\n",
      "145:\ttotal: 4.2s\tremaining: 24.6s\n",
      "146:\ttotal: 4.23s\tremaining: 24.5s\n",
      "147:\ttotal: 4.26s\tremaining: 24.5s\n",
      "148:\ttotal: 4.29s\tremaining: 24.5s\n",
      "149:\ttotal: 4.32s\tremaining: 24.5s\n",
      "150:\ttotal: 4.35s\tremaining: 24.4s\n",
      "151:\ttotal: 4.37s\tremaining: 24.4s\n",
      "152:\ttotal: 4.4s\tremaining: 24.4s\n",
      "153:\ttotal: 4.43s\tremaining: 24.4s\n",
      "154:\ttotal: 4.46s\tremaining: 24.3s\n",
      "155:\ttotal: 4.49s\tremaining: 24.3s\n",
      "156:\ttotal: 4.52s\tremaining: 24.3s\n",
      "157:\ttotal: 4.55s\tremaining: 24.2s\n",
      "158:\ttotal: 4.58s\tremaining: 24.2s\n",
      "159:\ttotal: 4.61s\tremaining: 24.2s\n",
      "160:\ttotal: 4.63s\tremaining: 24.2s\n",
      "161:\ttotal: 4.66s\tremaining: 24.1s\n",
      "162:\ttotal: 4.69s\tremaining: 24.1s\n",
      "163:\ttotal: 4.72s\tremaining: 24.1s\n",
      "164:\ttotal: 4.75s\tremaining: 24s\n",
      "165:\ttotal: 4.78s\tremaining: 24s\n",
      "166:\ttotal: 4.8s\tremaining: 24s\n",
      "167:\ttotal: 4.83s\tremaining: 23.9s\n",
      "168:\ttotal: 4.86s\tremaining: 23.9s\n",
      "169:\ttotal: 4.89s\tremaining: 23.9s\n",
      "170:\ttotal: 4.92s\tremaining: 23.8s\n",
      "171:\ttotal: 4.94s\tremaining: 23.8s\n",
      "172:\ttotal: 4.97s\tremaining: 23.8s\n",
      "173:\ttotal: 5s\tremaining: 23.7s\n",
      "174:\ttotal: 5.03s\tremaining: 23.7s\n",
      "175:\ttotal: 5.06s\tremaining: 23.7s\n",
      "176:\ttotal: 5.09s\tremaining: 23.7s\n",
      "177:\ttotal: 5.12s\tremaining: 23.6s\n",
      "178:\ttotal: 5.14s\tremaining: 23.6s\n",
      "179:\ttotal: 5.17s\tremaining: 23.6s\n",
      "180:\ttotal: 5.2s\tremaining: 23.5s\n",
      "181:\ttotal: 5.23s\tremaining: 23.5s\n",
      "182:\ttotal: 5.26s\tremaining: 23.5s\n",
      "183:\ttotal: 5.29s\tremaining: 23.5s\n",
      "184:\ttotal: 5.32s\tremaining: 23.4s\n",
      "185:\ttotal: 5.34s\tremaining: 23.4s\n",
      "186:\ttotal: 5.37s\tremaining: 23.4s\n",
      "187:\ttotal: 5.4s\tremaining: 23.3s\n",
      "188:\ttotal: 5.43s\tremaining: 23.3s\n",
      "189:\ttotal: 5.46s\tremaining: 23.3s\n",
      "190:\ttotal: 5.49s\tremaining: 23.2s\n",
      "191:\ttotal: 5.51s\tremaining: 23.2s\n",
      "192:\ttotal: 5.54s\tremaining: 23.2s\n",
      "193:\ttotal: 5.57s\tremaining: 23.1s\n",
      "194:\ttotal: 5.6s\tremaining: 23.1s\n",
      "195:\ttotal: 5.63s\tremaining: 23.1s\n",
      "196:\ttotal: 5.65s\tremaining: 23s\n",
      "197:\ttotal: 5.68s\tremaining: 23s\n",
      "198:\ttotal: 5.71s\tremaining: 23s\n",
      "199:\ttotal: 5.74s\tremaining: 22.9s\n",
      "200:\ttotal: 5.76s\tremaining: 22.9s\n",
      "201:\ttotal: 5.79s\tremaining: 22.9s\n",
      "202:\ttotal: 5.82s\tremaining: 22.8s\n",
      "203:\ttotal: 5.84s\tremaining: 22.8s\n",
      "204:\ttotal: 5.87s\tremaining: 22.8s\n",
      "205:\ttotal: 5.9s\tremaining: 22.7s\n",
      "206:\ttotal: 5.93s\tremaining: 22.7s\n",
      "207:\ttotal: 5.96s\tremaining: 22.7s\n",
      "208:\ttotal: 5.99s\tremaining: 22.7s\n",
      "209:\ttotal: 6.01s\tremaining: 22.6s\n",
      "210:\ttotal: 6.04s\tremaining: 22.6s\n",
      "211:\ttotal: 6.07s\tremaining: 22.6s\n",
      "212:\ttotal: 6.1s\tremaining: 22.5s\n",
      "213:\ttotal: 6.13s\tremaining: 22.5s\n",
      "214:\ttotal: 6.16s\tremaining: 22.5s\n",
      "215:\ttotal: 6.18s\tremaining: 22.4s\n",
      "216:\ttotal: 6.21s\tremaining: 22.4s\n",
      "217:\ttotal: 6.24s\tremaining: 22.4s\n",
      "218:\ttotal: 6.27s\tremaining: 22.4s\n",
      "219:\ttotal: 6.3s\tremaining: 22.3s\n",
      "220:\ttotal: 6.33s\tremaining: 22.3s\n",
      "221:\ttotal: 6.36s\tremaining: 22.3s\n",
      "222:\ttotal: 6.39s\tremaining: 22.3s\n",
      "223:\ttotal: 6.42s\tremaining: 22.2s\n",
      "224:\ttotal: 6.44s\tremaining: 22.2s\n",
      "225:\ttotal: 6.47s\tremaining: 22.2s\n",
      "226:\ttotal: 6.5s\tremaining: 22.1s\n",
      "227:\ttotal: 6.53s\tremaining: 22.1s\n",
      "228:\ttotal: 6.56s\tremaining: 22.1s\n",
      "229:\ttotal: 6.59s\tremaining: 22s\n",
      "230:\ttotal: 6.62s\tremaining: 22s\n",
      "231:\ttotal: 6.65s\tremaining: 22s\n",
      "232:\ttotal: 6.68s\tremaining: 22s\n",
      "233:\ttotal: 6.71s\tremaining: 22s\n",
      "234:\ttotal: 6.73s\tremaining: 21.9s\n",
      "235:\ttotal: 6.76s\tremaining: 21.9s\n",
      "236:\ttotal: 6.79s\tremaining: 21.9s\n",
      "237:\ttotal: 6.82s\tremaining: 21.8s\n",
      "238:\ttotal: 6.85s\tremaining: 21.8s\n",
      "239:\ttotal: 6.88s\tremaining: 21.8s\n",
      "240:\ttotal: 6.91s\tremaining: 21.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241:\ttotal: 6.94s\tremaining: 21.7s\n",
      "242:\ttotal: 6.97s\tremaining: 21.7s\n",
      "243:\ttotal: 7s\tremaining: 21.7s\n",
      "244:\ttotal: 7.03s\tremaining: 21.6s\n",
      "245:\ttotal: 7.05s\tremaining: 21.6s\n",
      "246:\ttotal: 7.08s\tremaining: 21.6s\n",
      "247:\ttotal: 7.11s\tremaining: 21.6s\n",
      "248:\ttotal: 7.14s\tremaining: 21.5s\n",
      "249:\ttotal: 7.17s\tremaining: 21.5s\n",
      "250:\ttotal: 7.19s\tremaining: 21.5s\n",
      "251:\ttotal: 7.22s\tremaining: 21.4s\n",
      "252:\ttotal: 7.25s\tremaining: 21.4s\n",
      "253:\ttotal: 7.28s\tremaining: 21.4s\n",
      "254:\ttotal: 7.31s\tremaining: 21.3s\n",
      "255:\ttotal: 7.33s\tremaining: 21.3s\n",
      "256:\ttotal: 7.36s\tremaining: 21.3s\n",
      "257:\ttotal: 7.39s\tremaining: 21.3s\n",
      "258:\ttotal: 7.42s\tremaining: 21.2s\n",
      "259:\ttotal: 7.45s\tremaining: 21.2s\n",
      "260:\ttotal: 7.48s\tremaining: 21.2s\n",
      "261:\ttotal: 7.5s\tremaining: 21.1s\n",
      "262:\ttotal: 7.53s\tremaining: 21.1s\n",
      "263:\ttotal: 7.56s\tremaining: 21.1s\n",
      "264:\ttotal: 7.59s\tremaining: 21.1s\n",
      "265:\ttotal: 7.62s\tremaining: 21s\n",
      "266:\ttotal: 7.65s\tremaining: 21s\n",
      "267:\ttotal: 7.67s\tremaining: 21s\n",
      "268:\ttotal: 7.71s\tremaining: 20.9s\n",
      "269:\ttotal: 7.73s\tremaining: 20.9s\n",
      "270:\ttotal: 7.76s\tremaining: 20.9s\n",
      "271:\ttotal: 7.79s\tremaining: 20.9s\n",
      "272:\ttotal: 7.82s\tremaining: 20.8s\n",
      "273:\ttotal: 7.85s\tremaining: 20.8s\n",
      "274:\ttotal: 7.88s\tremaining: 20.8s\n",
      "275:\ttotal: 7.9s\tremaining: 20.7s\n",
      "276:\ttotal: 7.93s\tremaining: 20.7s\n",
      "277:\ttotal: 7.96s\tremaining: 20.7s\n",
      "278:\ttotal: 7.99s\tremaining: 20.6s\n",
      "279:\ttotal: 8.02s\tremaining: 20.6s\n",
      "280:\ttotal: 8.04s\tremaining: 20.6s\n",
      "281:\ttotal: 8.07s\tremaining: 20.6s\n",
      "282:\ttotal: 8.11s\tremaining: 20.5s\n",
      "283:\ttotal: 8.13s\tremaining: 20.5s\n",
      "284:\ttotal: 8.16s\tremaining: 20.5s\n",
      "285:\ttotal: 8.19s\tremaining: 20.4s\n",
      "286:\ttotal: 8.22s\tremaining: 20.4s\n",
      "287:\ttotal: 8.25s\tremaining: 20.4s\n",
      "288:\ttotal: 8.28s\tremaining: 20.4s\n",
      "289:\ttotal: 8.3s\tremaining: 20.3s\n",
      "290:\ttotal: 8.34s\tremaining: 20.3s\n",
      "291:\ttotal: 8.37s\tremaining: 20.3s\n",
      "292:\ttotal: 8.39s\tremaining: 20.3s\n",
      "293:\ttotal: 8.42s\tremaining: 20.2s\n",
      "294:\ttotal: 8.45s\tremaining: 20.2s\n",
      "295:\ttotal: 8.48s\tremaining: 20.2s\n",
      "296:\ttotal: 8.51s\tremaining: 20.1s\n",
      "297:\ttotal: 8.54s\tremaining: 20.1s\n",
      "298:\ttotal: 8.57s\tremaining: 20.1s\n",
      "299:\ttotal: 8.6s\tremaining: 20.1s\n",
      "300:\ttotal: 8.63s\tremaining: 20s\n",
      "301:\ttotal: 8.66s\tremaining: 20s\n",
      "302:\ttotal: 8.68s\tremaining: 20s\n",
      "303:\ttotal: 8.71s\tremaining: 19.9s\n",
      "304:\ttotal: 8.74s\tremaining: 19.9s\n",
      "305:\ttotal: 8.77s\tremaining: 19.9s\n",
      "306:\ttotal: 8.8s\tremaining: 19.9s\n",
      "307:\ttotal: 8.83s\tremaining: 19.8s\n",
      "308:\ttotal: 8.86s\tremaining: 19.8s\n",
      "309:\ttotal: 8.89s\tremaining: 19.8s\n",
      "310:\ttotal: 8.92s\tremaining: 19.8s\n",
      "311:\ttotal: 8.95s\tremaining: 19.7s\n",
      "312:\ttotal: 8.98s\tremaining: 19.7s\n",
      "313:\ttotal: 9.01s\tremaining: 19.7s\n",
      "314:\ttotal: 9.04s\tremaining: 19.6s\n",
      "315:\ttotal: 9.07s\tremaining: 19.6s\n",
      "316:\ttotal: 9.1s\tremaining: 19.6s\n",
      "317:\ttotal: 9.12s\tremaining: 19.6s\n",
      "318:\ttotal: 9.15s\tremaining: 19.5s\n",
      "319:\ttotal: 9.18s\tremaining: 19.5s\n",
      "320:\ttotal: 9.21s\tremaining: 19.5s\n",
      "321:\ttotal: 9.24s\tremaining: 19.5s\n",
      "322:\ttotal: 9.27s\tremaining: 19.4s\n",
      "323:\ttotal: 9.3s\tremaining: 19.4s\n",
      "324:\ttotal: 9.33s\tremaining: 19.4s\n",
      "325:\ttotal: 9.36s\tremaining: 19.3s\n",
      "326:\ttotal: 9.39s\tremaining: 19.3s\n",
      "327:\ttotal: 9.41s\tremaining: 19.3s\n",
      "328:\ttotal: 9.44s\tremaining: 19.3s\n",
      "329:\ttotal: 9.47s\tremaining: 19.2s\n",
      "330:\ttotal: 9.5s\tremaining: 19.2s\n",
      "331:\ttotal: 9.53s\tremaining: 19.2s\n",
      "332:\ttotal: 9.56s\tremaining: 19.1s\n",
      "333:\ttotal: 9.59s\tremaining: 19.1s\n",
      "334:\ttotal: 9.62s\tremaining: 19.1s\n",
      "335:\ttotal: 9.65s\tremaining: 19.1s\n",
      "336:\ttotal: 9.68s\tremaining: 19s\n",
      "337:\ttotal: 9.71s\tremaining: 19s\n",
      "338:\ttotal: 9.73s\tremaining: 19s\n",
      "339:\ttotal: 9.76s\tremaining: 18.9s\n",
      "340:\ttotal: 9.79s\tremaining: 18.9s\n",
      "341:\ttotal: 9.82s\tremaining: 18.9s\n",
      "342:\ttotal: 9.85s\tremaining: 18.9s\n",
      "343:\ttotal: 9.87s\tremaining: 18.8s\n",
      "344:\ttotal: 9.9s\tremaining: 18.8s\n",
      "345:\ttotal: 9.93s\tremaining: 18.8s\n",
      "346:\ttotal: 9.96s\tremaining: 18.7s\n",
      "347:\ttotal: 9.99s\tremaining: 18.7s\n",
      "348:\ttotal: 10s\tremaining: 18.7s\n",
      "349:\ttotal: 10s\tremaining: 18.7s\n",
      "350:\ttotal: 10.1s\tremaining: 18.6s\n",
      "351:\ttotal: 10.1s\tremaining: 18.6s\n",
      "352:\ttotal: 10.1s\tremaining: 18.6s\n",
      "353:\ttotal: 10.2s\tremaining: 18.5s\n",
      "354:\ttotal: 10.2s\tremaining: 18.5s\n",
      "355:\ttotal: 10.2s\tremaining: 18.5s\n",
      "356:\ttotal: 10.2s\tremaining: 18.5s\n",
      "357:\ttotal: 10.3s\tremaining: 18.4s\n",
      "358:\ttotal: 10.3s\tremaining: 18.4s\n",
      "359:\ttotal: 10.3s\tremaining: 18.4s\n",
      "360:\ttotal: 10.4s\tremaining: 18.3s\n",
      "361:\ttotal: 10.4s\tremaining: 18.3s\n",
      "362:\ttotal: 10.4s\tremaining: 18.3s\n",
      "363:\ttotal: 10.5s\tremaining: 18.3s\n",
      "364:\ttotal: 10.5s\tremaining: 18.2s\n",
      "365:\ttotal: 10.5s\tremaining: 18.2s\n",
      "366:\ttotal: 10.5s\tremaining: 18.2s\n",
      "367:\ttotal: 10.6s\tremaining: 18.1s\n",
      "368:\ttotal: 10.6s\tremaining: 18.1s\n",
      "369:\ttotal: 10.6s\tremaining: 18.1s\n",
      "370:\ttotal: 10.7s\tremaining: 18.1s\n",
      "371:\ttotal: 10.7s\tremaining: 18s\n",
      "372:\ttotal: 10.7s\tremaining: 18s\n",
      "373:\ttotal: 10.7s\tremaining: 18s\n",
      "374:\ttotal: 10.8s\tremaining: 18s\n",
      "375:\ttotal: 10.8s\tremaining: 17.9s\n",
      "376:\ttotal: 10.8s\tremaining: 17.9s\n",
      "377:\ttotal: 10.9s\tremaining: 17.9s\n",
      "378:\ttotal: 10.9s\tremaining: 17.8s\n",
      "379:\ttotal: 10.9s\tremaining: 17.8s\n",
      "380:\ttotal: 10.9s\tremaining: 17.8s\n",
      "381:\ttotal: 11s\tremaining: 17.8s\n",
      "382:\ttotal: 11s\tremaining: 17.7s\n",
      "383:\ttotal: 11s\tremaining: 17.7s\n",
      "384:\ttotal: 11.1s\tremaining: 17.7s\n",
      "385:\ttotal: 11.1s\tremaining: 17.6s\n",
      "386:\ttotal: 11.1s\tremaining: 17.6s\n",
      "387:\ttotal: 11.1s\tremaining: 17.6s\n",
      "388:\ttotal: 11.2s\tremaining: 17.6s\n",
      "389:\ttotal: 11.2s\tremaining: 17.5s\n",
      "390:\ttotal: 11.2s\tremaining: 17.5s\n",
      "391:\ttotal: 11.3s\tremaining: 17.5s\n",
      "392:\ttotal: 11.3s\tremaining: 17.5s\n",
      "393:\ttotal: 11.3s\tremaining: 17.4s\n",
      "394:\ttotal: 11.4s\tremaining: 17.4s\n",
      "395:\ttotal: 11.4s\tremaining: 17.4s\n",
      "396:\ttotal: 11.4s\tremaining: 17.3s\n",
      "397:\ttotal: 11.4s\tremaining: 17.3s\n",
      "398:\ttotal: 11.5s\tremaining: 17.3s\n",
      "399:\ttotal: 11.5s\tremaining: 17.3s\n",
      "400:\ttotal: 11.5s\tremaining: 17.2s\n",
      "401:\ttotal: 11.6s\tremaining: 17.2s\n",
      "402:\ttotal: 11.6s\tremaining: 17.2s\n",
      "403:\ttotal: 11.6s\tremaining: 17.1s\n",
      "404:\ttotal: 11.7s\tremaining: 17.1s\n",
      "405:\ttotal: 11.7s\tremaining: 17.1s\n",
      "406:\ttotal: 11.7s\tremaining: 17.1s\n",
      "407:\ttotal: 11.7s\tremaining: 17s\n",
      "408:\ttotal: 11.8s\tremaining: 17s\n",
      "409:\ttotal: 11.8s\tremaining: 17s\n",
      "410:\ttotal: 11.8s\tremaining: 16.9s\n",
      "411:\ttotal: 11.9s\tremaining: 16.9s\n",
      "412:\ttotal: 11.9s\tremaining: 16.9s\n",
      "413:\ttotal: 11.9s\tremaining: 16.9s\n",
      "414:\ttotal: 11.9s\tremaining: 16.8s\n",
      "415:\ttotal: 12s\tremaining: 16.8s\n",
      "416:\ttotal: 12s\tremaining: 16.8s\n",
      "417:\ttotal: 12s\tremaining: 16.7s\n",
      "418:\ttotal: 12.1s\tremaining: 16.7s\n",
      "419:\ttotal: 12.1s\tremaining: 16.7s\n",
      "420:\ttotal: 12.1s\tremaining: 16.7s\n",
      "421:\ttotal: 12.1s\tremaining: 16.6s\n",
      "422:\ttotal: 12.2s\tremaining: 16.6s\n",
      "423:\ttotal: 12.2s\tremaining: 16.6s\n",
      "424:\ttotal: 12.2s\tremaining: 16.5s\n",
      "425:\ttotal: 12.3s\tremaining: 16.5s\n",
      "426:\ttotal: 12.3s\tremaining: 16.5s\n",
      "427:\ttotal: 12.3s\tremaining: 16.5s\n",
      "428:\ttotal: 12.3s\tremaining: 16.4s\n",
      "429:\ttotal: 12.4s\tremaining: 16.4s\n",
      "430:\ttotal: 12.4s\tremaining: 16.4s\n",
      "431:\ttotal: 12.4s\tremaining: 16.3s\n",
      "432:\ttotal: 12.5s\tremaining: 16.3s\n",
      "433:\ttotal: 12.5s\tremaining: 16.3s\n",
      "434:\ttotal: 12.5s\tremaining: 16.3s\n",
      "435:\ttotal: 12.5s\tremaining: 16.2s\n",
      "436:\ttotal: 12.6s\tremaining: 16.2s\n",
      "437:\ttotal: 12.6s\tremaining: 16.2s\n",
      "438:\ttotal: 12.6s\tremaining: 16.1s\n",
      "439:\ttotal: 12.7s\tremaining: 16.1s\n",
      "440:\ttotal: 12.7s\tremaining: 16.1s\n",
      "441:\ttotal: 12.7s\tremaining: 16.1s\n",
      "442:\ttotal: 12.8s\tremaining: 16s\n",
      "443:\ttotal: 12.8s\tremaining: 16s\n",
      "444:\ttotal: 12.8s\tremaining: 16s\n",
      "445:\ttotal: 12.8s\tremaining: 16s\n",
      "446:\ttotal: 12.9s\tremaining: 15.9s\n",
      "447:\ttotal: 12.9s\tremaining: 15.9s\n",
      "448:\ttotal: 12.9s\tremaining: 15.9s\n",
      "449:\ttotal: 13s\tremaining: 15.8s\n",
      "450:\ttotal: 13s\tremaining: 15.8s\n",
      "451:\ttotal: 13s\tremaining: 15.8s\n",
      "452:\ttotal: 13s\tremaining: 15.8s\n",
      "453:\ttotal: 13.1s\tremaining: 15.7s\n",
      "454:\ttotal: 13.1s\tremaining: 15.7s\n",
      "455:\ttotal: 13.1s\tremaining: 15.7s\n",
      "456:\ttotal: 13.2s\tremaining: 15.6s\n",
      "457:\ttotal: 13.2s\tremaining: 15.6s\n",
      "458:\ttotal: 13.2s\tremaining: 15.6s\n",
      "459:\ttotal: 13.2s\tremaining: 15.6s\n",
      "460:\ttotal: 13.3s\tremaining: 15.5s\n",
      "461:\ttotal: 13.3s\tremaining: 15.5s\n",
      "462:\ttotal: 13.3s\tremaining: 15.5s\n",
      "463:\ttotal: 13.4s\tremaining: 15.4s\n",
      "464:\ttotal: 13.4s\tremaining: 15.4s\n",
      "465:\ttotal: 13.4s\tremaining: 15.4s\n",
      "466:\ttotal: 13.4s\tremaining: 15.3s\n",
      "467:\ttotal: 13.5s\tremaining: 15.3s\n",
      "468:\ttotal: 13.5s\tremaining: 15.3s\n",
      "469:\ttotal: 13.5s\tremaining: 15.3s\n",
      "470:\ttotal: 13.6s\tremaining: 15.2s\n",
      "471:\ttotal: 13.6s\tremaining: 15.2s\n",
      "472:\ttotal: 13.6s\tremaining: 15.2s\n",
      "473:\ttotal: 13.6s\tremaining: 15.1s\n",
      "474:\ttotal: 13.7s\tremaining: 15.1s\n",
      "475:\ttotal: 13.7s\tremaining: 15.1s\n",
      "476:\ttotal: 13.7s\tremaining: 15.1s\n",
      "477:\ttotal: 13.8s\tremaining: 15s\n",
      "478:\ttotal: 13.8s\tremaining: 15s\n",
      "479:\ttotal: 13.8s\tremaining: 15s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480:\ttotal: 13.8s\tremaining: 14.9s\n",
      "481:\ttotal: 13.9s\tremaining: 14.9s\n",
      "482:\ttotal: 13.9s\tremaining: 14.9s\n",
      "483:\ttotal: 13.9s\tremaining: 14.9s\n",
      "484:\ttotal: 14s\tremaining: 14.8s\n",
      "485:\ttotal: 14s\tremaining: 14.8s\n",
      "486:\ttotal: 14s\tremaining: 14.8s\n",
      "487:\ttotal: 14s\tremaining: 14.7s\n",
      "488:\ttotal: 14.1s\tremaining: 14.7s\n",
      "489:\ttotal: 14.1s\tremaining: 14.7s\n",
      "490:\ttotal: 14.1s\tremaining: 14.7s\n",
      "491:\ttotal: 14.2s\tremaining: 14.6s\n",
      "492:\ttotal: 14.2s\tremaining: 14.6s\n",
      "493:\ttotal: 14.2s\tremaining: 14.6s\n",
      "494:\ttotal: 14.3s\tremaining: 14.5s\n",
      "495:\ttotal: 14.3s\tremaining: 14.5s\n",
      "496:\ttotal: 14.3s\tremaining: 14.5s\n",
      "497:\ttotal: 14.3s\tremaining: 14.5s\n",
      "498:\ttotal: 14.4s\tremaining: 14.4s\n",
      "499:\ttotal: 14.4s\tremaining: 14.4s\n",
      "500:\ttotal: 14.4s\tremaining: 14.4s\n",
      "501:\ttotal: 14.5s\tremaining: 14.3s\n",
      "502:\ttotal: 14.5s\tremaining: 14.3s\n",
      "503:\ttotal: 14.5s\tremaining: 14.3s\n",
      "504:\ttotal: 14.5s\tremaining: 14.3s\n",
      "505:\ttotal: 14.6s\tremaining: 14.2s\n",
      "506:\ttotal: 14.6s\tremaining: 14.2s\n",
      "507:\ttotal: 14.6s\tremaining: 14.2s\n",
      "508:\ttotal: 14.7s\tremaining: 14.2s\n",
      "509:\ttotal: 14.7s\tremaining: 14.1s\n",
      "510:\ttotal: 14.7s\tremaining: 14.1s\n",
      "511:\ttotal: 14.8s\tremaining: 14.1s\n",
      "512:\ttotal: 14.8s\tremaining: 14s\n",
      "513:\ttotal: 14.8s\tremaining: 14s\n",
      "514:\ttotal: 14.8s\tremaining: 14s\n",
      "515:\ttotal: 14.9s\tremaining: 14s\n",
      "516:\ttotal: 14.9s\tremaining: 13.9s\n",
      "517:\ttotal: 14.9s\tremaining: 13.9s\n",
      "518:\ttotal: 15s\tremaining: 13.9s\n",
      "519:\ttotal: 15s\tremaining: 13.8s\n",
      "520:\ttotal: 15s\tremaining: 13.8s\n",
      "521:\ttotal: 15s\tremaining: 13.8s\n",
      "522:\ttotal: 15.1s\tremaining: 13.8s\n",
      "523:\ttotal: 15.1s\tremaining: 13.7s\n",
      "524:\ttotal: 15.1s\tremaining: 13.7s\n",
      "525:\ttotal: 15.2s\tremaining: 13.7s\n",
      "526:\ttotal: 15.2s\tremaining: 13.6s\n",
      "527:\ttotal: 15.2s\tremaining: 13.6s\n",
      "528:\ttotal: 15.3s\tremaining: 13.6s\n",
      "529:\ttotal: 15.3s\tremaining: 13.6s\n",
      "530:\ttotal: 15.3s\tremaining: 13.5s\n",
      "531:\ttotal: 15.3s\tremaining: 13.5s\n",
      "532:\ttotal: 15.4s\tremaining: 13.5s\n",
      "533:\ttotal: 15.4s\tremaining: 13.4s\n",
      "534:\ttotal: 15.4s\tremaining: 13.4s\n",
      "535:\ttotal: 15.5s\tremaining: 13.4s\n",
      "536:\ttotal: 15.5s\tremaining: 13.4s\n",
      "537:\ttotal: 15.5s\tremaining: 13.3s\n",
      "538:\ttotal: 15.5s\tremaining: 13.3s\n",
      "539:\ttotal: 15.6s\tremaining: 13.3s\n",
      "540:\ttotal: 15.6s\tremaining: 13.2s\n",
      "541:\ttotal: 15.6s\tremaining: 13.2s\n",
      "542:\ttotal: 15.7s\tremaining: 13.2s\n",
      "543:\ttotal: 15.7s\tremaining: 13.2s\n",
      "544:\ttotal: 15.7s\tremaining: 13.1s\n",
      "545:\ttotal: 15.7s\tremaining: 13.1s\n",
      "546:\ttotal: 15.8s\tremaining: 13.1s\n",
      "547:\ttotal: 15.8s\tremaining: 13s\n",
      "548:\ttotal: 15.8s\tremaining: 13s\n",
      "549:\ttotal: 15.9s\tremaining: 13s\n",
      "550:\ttotal: 15.9s\tremaining: 12.9s\n",
      "551:\ttotal: 15.9s\tremaining: 12.9s\n",
      "552:\ttotal: 15.9s\tremaining: 12.9s\n",
      "553:\ttotal: 16s\tremaining: 12.9s\n",
      "554:\ttotal: 16s\tremaining: 12.8s\n",
      "555:\ttotal: 16s\tremaining: 12.8s\n",
      "556:\ttotal: 16.1s\tremaining: 12.8s\n",
      "557:\ttotal: 16.1s\tremaining: 12.7s\n",
      "558:\ttotal: 16.1s\tremaining: 12.7s\n",
      "559:\ttotal: 16.1s\tremaining: 12.7s\n",
      "560:\ttotal: 16.2s\tremaining: 12.7s\n",
      "561:\ttotal: 16.2s\tremaining: 12.6s\n",
      "562:\ttotal: 16.2s\tremaining: 12.6s\n",
      "563:\ttotal: 16.3s\tremaining: 12.6s\n",
      "564:\ttotal: 16.3s\tremaining: 12.5s\n",
      "565:\ttotal: 16.3s\tremaining: 12.5s\n",
      "566:\ttotal: 16.3s\tremaining: 12.5s\n",
      "567:\ttotal: 16.4s\tremaining: 12.5s\n",
      "568:\ttotal: 16.4s\tremaining: 12.4s\n",
      "569:\ttotal: 16.4s\tremaining: 12.4s\n",
      "570:\ttotal: 16.5s\tremaining: 12.4s\n",
      "571:\ttotal: 16.5s\tremaining: 12.3s\n",
      "572:\ttotal: 16.5s\tremaining: 12.3s\n",
      "573:\ttotal: 16.6s\tremaining: 12.3s\n",
      "574:\ttotal: 16.6s\tremaining: 12.3s\n",
      "575:\ttotal: 16.6s\tremaining: 12.2s\n",
      "576:\ttotal: 16.6s\tremaining: 12.2s\n",
      "577:\ttotal: 16.7s\tremaining: 12.2s\n",
      "578:\ttotal: 16.7s\tremaining: 12.1s\n",
      "579:\ttotal: 16.7s\tremaining: 12.1s\n",
      "580:\ttotal: 16.8s\tremaining: 12.1s\n",
      "581:\ttotal: 16.8s\tremaining: 12.1s\n",
      "582:\ttotal: 16.8s\tremaining: 12s\n",
      "583:\ttotal: 16.8s\tremaining: 12s\n",
      "584:\ttotal: 16.9s\tremaining: 12s\n",
      "585:\ttotal: 16.9s\tremaining: 11.9s\n",
      "586:\ttotal: 16.9s\tremaining: 11.9s\n",
      "587:\ttotal: 17s\tremaining: 11.9s\n",
      "588:\ttotal: 17s\tremaining: 11.9s\n",
      "589:\ttotal: 17s\tremaining: 11.8s\n",
      "590:\ttotal: 17s\tremaining: 11.8s\n",
      "591:\ttotal: 17.1s\tremaining: 11.8s\n",
      "592:\ttotal: 17.1s\tremaining: 11.7s\n",
      "593:\ttotal: 17.1s\tremaining: 11.7s\n",
      "594:\ttotal: 17.2s\tremaining: 11.7s\n",
      "595:\ttotal: 17.2s\tremaining: 11.7s\n",
      "596:\ttotal: 17.2s\tremaining: 11.6s\n",
      "597:\ttotal: 17.2s\tremaining: 11.6s\n",
      "598:\ttotal: 17.3s\tremaining: 11.6s\n",
      "599:\ttotal: 17.3s\tremaining: 11.5s\n",
      "600:\ttotal: 17.3s\tremaining: 11.5s\n",
      "601:\ttotal: 17.4s\tremaining: 11.5s\n",
      "602:\ttotal: 17.4s\tremaining: 11.5s\n",
      "603:\ttotal: 17.4s\tremaining: 11.4s\n",
      "604:\ttotal: 17.5s\tremaining: 11.4s\n",
      "605:\ttotal: 17.5s\tremaining: 11.4s\n",
      "606:\ttotal: 17.5s\tremaining: 11.3s\n",
      "607:\ttotal: 17.5s\tremaining: 11.3s\n",
      "608:\ttotal: 17.6s\tremaining: 11.3s\n",
      "609:\ttotal: 17.6s\tremaining: 11.3s\n",
      "610:\ttotal: 17.6s\tremaining: 11.2s\n",
      "611:\ttotal: 17.7s\tremaining: 11.2s\n",
      "612:\ttotal: 17.7s\tremaining: 11.2s\n",
      "613:\ttotal: 17.7s\tremaining: 11.1s\n",
      "614:\ttotal: 17.7s\tremaining: 11.1s\n",
      "615:\ttotal: 17.8s\tremaining: 11.1s\n",
      "616:\ttotal: 17.8s\tremaining: 11.1s\n",
      "617:\ttotal: 17.8s\tremaining: 11s\n",
      "618:\ttotal: 17.9s\tremaining: 11s\n",
      "619:\ttotal: 17.9s\tremaining: 11s\n",
      "620:\ttotal: 17.9s\tremaining: 10.9s\n",
      "621:\ttotal: 17.9s\tremaining: 10.9s\n",
      "622:\ttotal: 18s\tremaining: 10.9s\n",
      "623:\ttotal: 18s\tremaining: 10.8s\n",
      "624:\ttotal: 18s\tremaining: 10.8s\n",
      "625:\ttotal: 18.1s\tremaining: 10.8s\n",
      "626:\ttotal: 18.1s\tremaining: 10.8s\n",
      "627:\ttotal: 18.1s\tremaining: 10.7s\n",
      "628:\ttotal: 18.1s\tremaining: 10.7s\n",
      "629:\ttotal: 18.2s\tremaining: 10.7s\n",
      "630:\ttotal: 18.2s\tremaining: 10.6s\n",
      "631:\ttotal: 18.2s\tremaining: 10.6s\n",
      "632:\ttotal: 18.3s\tremaining: 10.6s\n",
      "633:\ttotal: 18.3s\tremaining: 10.6s\n",
      "634:\ttotal: 18.3s\tremaining: 10.5s\n",
      "635:\ttotal: 18.3s\tremaining: 10.5s\n",
      "636:\ttotal: 18.4s\tremaining: 10.5s\n",
      "637:\ttotal: 18.4s\tremaining: 10.4s\n",
      "638:\ttotal: 18.4s\tremaining: 10.4s\n",
      "639:\ttotal: 18.5s\tremaining: 10.4s\n",
      "640:\ttotal: 18.5s\tremaining: 10.4s\n",
      "641:\ttotal: 18.5s\tremaining: 10.3s\n",
      "642:\ttotal: 18.6s\tremaining: 10.3s\n",
      "643:\ttotal: 18.6s\tremaining: 10.3s\n",
      "644:\ttotal: 18.6s\tremaining: 10.2s\n",
      "645:\ttotal: 18.6s\tremaining: 10.2s\n",
      "646:\ttotal: 18.7s\tremaining: 10.2s\n",
      "647:\ttotal: 18.7s\tremaining: 10.2s\n",
      "648:\ttotal: 18.7s\tremaining: 10.1s\n",
      "649:\ttotal: 18.8s\tremaining: 10.1s\n",
      "650:\ttotal: 18.8s\tremaining: 10.1s\n",
      "651:\ttotal: 18.8s\tremaining: 10s\n",
      "652:\ttotal: 18.8s\tremaining: 10s\n",
      "653:\ttotal: 18.9s\tremaining: 9.98s\n",
      "654:\ttotal: 18.9s\tremaining: 9.95s\n",
      "655:\ttotal: 18.9s\tremaining: 9.92s\n",
      "656:\ttotal: 19s\tremaining: 9.89s\n",
      "657:\ttotal: 19s\tremaining: 9.87s\n",
      "658:\ttotal: 19s\tremaining: 9.84s\n",
      "659:\ttotal: 19s\tremaining: 9.81s\n",
      "660:\ttotal: 19.1s\tremaining: 9.78s\n",
      "661:\ttotal: 19.1s\tremaining: 9.75s\n",
      "662:\ttotal: 19.1s\tremaining: 9.72s\n",
      "663:\ttotal: 19.2s\tremaining: 9.69s\n",
      "664:\ttotal: 19.2s\tremaining: 9.67s\n",
      "665:\ttotal: 19.2s\tremaining: 9.64s\n",
      "666:\ttotal: 19.2s\tremaining: 9.61s\n",
      "667:\ttotal: 19.3s\tremaining: 9.58s\n",
      "668:\ttotal: 19.3s\tremaining: 9.55s\n",
      "669:\ttotal: 19.3s\tremaining: 9.52s\n",
      "670:\ttotal: 19.4s\tremaining: 9.49s\n",
      "671:\ttotal: 19.4s\tremaining: 9.46s\n",
      "672:\ttotal: 19.4s\tremaining: 9.44s\n",
      "673:\ttotal: 19.5s\tremaining: 9.41s\n",
      "674:\ttotal: 19.5s\tremaining: 9.38s\n",
      "675:\ttotal: 19.5s\tremaining: 9.35s\n",
      "676:\ttotal: 19.5s\tremaining: 9.32s\n",
      "677:\ttotal: 19.6s\tremaining: 9.29s\n",
      "678:\ttotal: 19.6s\tremaining: 9.26s\n",
      "679:\ttotal: 19.6s\tremaining: 9.23s\n",
      "680:\ttotal: 19.6s\tremaining: 9.2s\n",
      "681:\ttotal: 19.7s\tremaining: 9.18s\n",
      "682:\ttotal: 19.7s\tremaining: 9.15s\n",
      "683:\ttotal: 19.7s\tremaining: 9.12s\n",
      "684:\ttotal: 19.8s\tremaining: 9.09s\n",
      "685:\ttotal: 19.8s\tremaining: 9.06s\n",
      "686:\ttotal: 19.8s\tremaining: 9.03s\n",
      "687:\ttotal: 19.9s\tremaining: 9s\n",
      "688:\ttotal: 19.9s\tremaining: 8.97s\n",
      "689:\ttotal: 19.9s\tremaining: 8.95s\n",
      "690:\ttotal: 19.9s\tremaining: 8.92s\n",
      "691:\ttotal: 20s\tremaining: 8.89s\n",
      "692:\ttotal: 20s\tremaining: 8.86s\n",
      "693:\ttotal: 20s\tremaining: 8.83s\n",
      "694:\ttotal: 20.1s\tremaining: 8.8s\n",
      "695:\ttotal: 20.1s\tremaining: 8.77s\n",
      "696:\ttotal: 20.1s\tremaining: 8.74s\n",
      "697:\ttotal: 20.1s\tremaining: 8.72s\n",
      "698:\ttotal: 20.2s\tremaining: 8.69s\n",
      "699:\ttotal: 20.2s\tremaining: 8.66s\n",
      "700:\ttotal: 20.2s\tremaining: 8.63s\n",
      "701:\ttotal: 20.3s\tremaining: 8.6s\n",
      "702:\ttotal: 20.3s\tremaining: 8.57s\n",
      "703:\ttotal: 20.3s\tremaining: 8.54s\n",
      "704:\ttotal: 20.4s\tremaining: 8.52s\n",
      "705:\ttotal: 20.4s\tremaining: 8.49s\n",
      "706:\ttotal: 20.4s\tremaining: 8.46s\n",
      "707:\ttotal: 20.4s\tremaining: 8.43s\n",
      "708:\ttotal: 20.5s\tremaining: 8.4s\n",
      "709:\ttotal: 20.5s\tremaining: 8.37s\n",
      "710:\ttotal: 20.5s\tremaining: 8.34s\n",
      "711:\ttotal: 20.6s\tremaining: 8.31s\n",
      "712:\ttotal: 20.6s\tremaining: 8.28s\n",
      "713:\ttotal: 20.6s\tremaining: 8.26s\n",
      "714:\ttotal: 20.6s\tremaining: 8.23s\n",
      "715:\ttotal: 20.7s\tremaining: 8.2s\n",
      "716:\ttotal: 20.7s\tremaining: 8.17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717:\ttotal: 20.7s\tremaining: 8.14s\n",
      "718:\ttotal: 20.8s\tremaining: 8.11s\n",
      "719:\ttotal: 20.8s\tremaining: 8.08s\n",
      "720:\ttotal: 20.8s\tremaining: 8.05s\n",
      "721:\ttotal: 20.8s\tremaining: 8.02s\n",
      "722:\ttotal: 20.9s\tremaining: 8s\n",
      "723:\ttotal: 20.9s\tremaining: 7.97s\n",
      "724:\ttotal: 20.9s\tremaining: 7.94s\n",
      "725:\ttotal: 21s\tremaining: 7.91s\n",
      "726:\ttotal: 21s\tremaining: 7.88s\n",
      "727:\ttotal: 21s\tremaining: 7.85s\n",
      "728:\ttotal: 21s\tremaining: 7.82s\n",
      "729:\ttotal: 21.1s\tremaining: 7.79s\n",
      "730:\ttotal: 21.1s\tremaining: 7.76s\n",
      "731:\ttotal: 21.1s\tremaining: 7.73s\n",
      "732:\ttotal: 21.2s\tremaining: 7.71s\n",
      "733:\ttotal: 21.2s\tremaining: 7.68s\n",
      "734:\ttotal: 21.2s\tremaining: 7.65s\n",
      "735:\ttotal: 21.2s\tremaining: 7.62s\n",
      "736:\ttotal: 21.3s\tremaining: 7.59s\n",
      "737:\ttotal: 21.3s\tremaining: 7.56s\n",
      "738:\ttotal: 21.3s\tremaining: 7.53s\n",
      "739:\ttotal: 21.4s\tremaining: 7.5s\n",
      "740:\ttotal: 21.4s\tremaining: 7.48s\n",
      "741:\ttotal: 21.4s\tremaining: 7.45s\n",
      "742:\ttotal: 21.5s\tremaining: 7.42s\n",
      "743:\ttotal: 21.5s\tremaining: 7.39s\n",
      "744:\ttotal: 21.5s\tremaining: 7.36s\n",
      "745:\ttotal: 21.5s\tremaining: 7.33s\n",
      "746:\ttotal: 21.6s\tremaining: 7.3s\n",
      "747:\ttotal: 21.6s\tremaining: 7.28s\n",
      "748:\ttotal: 21.6s\tremaining: 7.25s\n",
      "749:\ttotal: 21.7s\tremaining: 7.22s\n",
      "750:\ttotal: 21.7s\tremaining: 7.19s\n",
      "751:\ttotal: 21.7s\tremaining: 7.16s\n",
      "752:\ttotal: 21.7s\tremaining: 7.13s\n",
      "753:\ttotal: 21.8s\tremaining: 7.1s\n",
      "754:\ttotal: 21.8s\tremaining: 7.07s\n",
      "755:\ttotal: 21.8s\tremaining: 7.05s\n",
      "756:\ttotal: 21.9s\tremaining: 7.02s\n",
      "757:\ttotal: 21.9s\tremaining: 6.99s\n",
      "758:\ttotal: 21.9s\tremaining: 6.96s\n",
      "759:\ttotal: 21.9s\tremaining: 6.93s\n",
      "760:\ttotal: 22s\tremaining: 6.9s\n",
      "761:\ttotal: 22s\tremaining: 6.87s\n",
      "762:\ttotal: 22s\tremaining: 6.84s\n",
      "763:\ttotal: 22.1s\tremaining: 6.81s\n",
      "764:\ttotal: 22.1s\tremaining: 6.78s\n",
      "765:\ttotal: 22.1s\tremaining: 6.75s\n",
      "766:\ttotal: 22.1s\tremaining: 6.73s\n",
      "767:\ttotal: 22.2s\tremaining: 6.7s\n",
      "768:\ttotal: 22.2s\tremaining: 6.67s\n",
      "769:\ttotal: 22.2s\tremaining: 6.64s\n",
      "770:\ttotal: 22.3s\tremaining: 6.61s\n",
      "771:\ttotal: 22.3s\tremaining: 6.58s\n",
      "772:\ttotal: 22.3s\tremaining: 6.55s\n",
      "773:\ttotal: 22.3s\tremaining: 6.53s\n",
      "774:\ttotal: 22.4s\tremaining: 6.5s\n",
      "775:\ttotal: 22.4s\tremaining: 6.47s\n",
      "776:\ttotal: 22.4s\tremaining: 6.44s\n",
      "777:\ttotal: 22.5s\tremaining: 6.41s\n",
      "778:\ttotal: 22.5s\tremaining: 6.38s\n",
      "779:\ttotal: 22.5s\tremaining: 6.35s\n",
      "780:\ttotal: 22.6s\tremaining: 6.32s\n",
      "781:\ttotal: 22.6s\tremaining: 6.29s\n",
      "782:\ttotal: 22.6s\tremaining: 6.27s\n",
      "783:\ttotal: 22.6s\tremaining: 6.24s\n",
      "784:\ttotal: 22.7s\tremaining: 6.21s\n",
      "785:\ttotal: 22.7s\tremaining: 6.18s\n",
      "786:\ttotal: 22.7s\tremaining: 6.15s\n",
      "787:\ttotal: 22.8s\tremaining: 6.12s\n",
      "788:\ttotal: 22.8s\tremaining: 6.09s\n",
      "789:\ttotal: 22.8s\tremaining: 6.06s\n",
      "790:\ttotal: 22.8s\tremaining: 6.04s\n",
      "791:\ttotal: 22.9s\tremaining: 6.01s\n",
      "792:\ttotal: 22.9s\tremaining: 5.98s\n",
      "793:\ttotal: 22.9s\tremaining: 5.95s\n",
      "794:\ttotal: 23s\tremaining: 5.92s\n",
      "795:\ttotal: 23s\tremaining: 5.89s\n",
      "796:\ttotal: 23s\tremaining: 5.86s\n",
      "797:\ttotal: 23s\tremaining: 5.83s\n",
      "798:\ttotal: 23.1s\tremaining: 5.8s\n",
      "799:\ttotal: 23.1s\tremaining: 5.77s\n",
      "800:\ttotal: 23.1s\tremaining: 5.74s\n",
      "801:\ttotal: 23.2s\tremaining: 5.71s\n",
      "802:\ttotal: 23.2s\tremaining: 5.69s\n",
      "803:\ttotal: 23.2s\tremaining: 5.66s\n",
      "804:\ttotal: 23.2s\tremaining: 5.63s\n",
      "805:\ttotal: 23.3s\tremaining: 5.6s\n",
      "806:\ttotal: 23.3s\tremaining: 5.57s\n",
      "807:\ttotal: 23.3s\tremaining: 5.54s\n",
      "808:\ttotal: 23.4s\tremaining: 5.51s\n",
      "809:\ttotal: 23.4s\tremaining: 5.48s\n",
      "810:\ttotal: 23.4s\tremaining: 5.46s\n",
      "811:\ttotal: 23.4s\tremaining: 5.43s\n",
      "812:\ttotal: 23.5s\tremaining: 5.4s\n",
      "813:\ttotal: 23.5s\tremaining: 5.37s\n",
      "814:\ttotal: 23.5s\tremaining: 5.34s\n",
      "815:\ttotal: 23.6s\tremaining: 5.31s\n",
      "816:\ttotal: 23.6s\tremaining: 5.28s\n",
      "817:\ttotal: 23.6s\tremaining: 5.25s\n",
      "818:\ttotal: 23.7s\tremaining: 5.23s\n",
      "819:\ttotal: 23.7s\tremaining: 5.2s\n",
      "820:\ttotal: 23.7s\tremaining: 5.17s\n",
      "821:\ttotal: 23.7s\tremaining: 5.14s\n",
      "822:\ttotal: 23.8s\tremaining: 5.11s\n",
      "823:\ttotal: 23.8s\tremaining: 5.08s\n",
      "824:\ttotal: 23.8s\tremaining: 5.05s\n",
      "825:\ttotal: 23.9s\tremaining: 5.03s\n",
      "826:\ttotal: 23.9s\tremaining: 5s\n",
      "827:\ttotal: 23.9s\tremaining: 4.97s\n",
      "828:\ttotal: 23.9s\tremaining: 4.94s\n",
      "829:\ttotal: 24s\tremaining: 4.91s\n",
      "830:\ttotal: 24s\tremaining: 4.88s\n",
      "831:\ttotal: 24s\tremaining: 4.85s\n",
      "832:\ttotal: 24.1s\tremaining: 4.82s\n",
      "833:\ttotal: 24.1s\tremaining: 4.79s\n",
      "834:\ttotal: 24.1s\tremaining: 4.76s\n",
      "835:\ttotal: 24.1s\tremaining: 4.74s\n",
      "836:\ttotal: 24.2s\tremaining: 4.71s\n",
      "837:\ttotal: 24.2s\tremaining: 4.68s\n",
      "838:\ttotal: 24.2s\tremaining: 4.65s\n",
      "839:\ttotal: 24.3s\tremaining: 4.62s\n",
      "840:\ttotal: 24.3s\tremaining: 4.59s\n",
      "841:\ttotal: 24.3s\tremaining: 4.56s\n",
      "842:\ttotal: 24.3s\tremaining: 4.53s\n",
      "843:\ttotal: 24.4s\tremaining: 4.5s\n",
      "844:\ttotal: 24.4s\tremaining: 4.47s\n",
      "845:\ttotal: 24.4s\tremaining: 4.45s\n",
      "846:\ttotal: 24.5s\tremaining: 4.42s\n",
      "847:\ttotal: 24.5s\tremaining: 4.39s\n",
      "848:\ttotal: 24.5s\tremaining: 4.36s\n",
      "849:\ttotal: 24.5s\tremaining: 4.33s\n",
      "850:\ttotal: 24.6s\tremaining: 4.3s\n",
      "851:\ttotal: 24.6s\tremaining: 4.27s\n",
      "852:\ttotal: 24.6s\tremaining: 4.25s\n",
      "853:\ttotal: 24.7s\tremaining: 4.21s\n",
      "854:\ttotal: 24.7s\tremaining: 4.19s\n",
      "855:\ttotal: 24.7s\tremaining: 4.16s\n",
      "856:\ttotal: 24.7s\tremaining: 4.13s\n",
      "857:\ttotal: 24.8s\tremaining: 4.1s\n",
      "858:\ttotal: 24.8s\tremaining: 4.07s\n",
      "859:\ttotal: 24.8s\tremaining: 4.04s\n",
      "860:\ttotal: 24.9s\tremaining: 4.01s\n",
      "861:\ttotal: 24.9s\tremaining: 3.98s\n",
      "862:\ttotal: 24.9s\tremaining: 3.96s\n",
      "863:\ttotal: 24.9s\tremaining: 3.93s\n",
      "864:\ttotal: 25s\tremaining: 3.9s\n",
      "865:\ttotal: 25s\tremaining: 3.87s\n",
      "866:\ttotal: 25s\tremaining: 3.84s\n",
      "867:\ttotal: 25.1s\tremaining: 3.81s\n",
      "868:\ttotal: 25.1s\tremaining: 3.78s\n",
      "869:\ttotal: 25.1s\tremaining: 3.75s\n",
      "870:\ttotal: 25.2s\tremaining: 3.73s\n",
      "871:\ttotal: 25.2s\tremaining: 3.7s\n",
      "872:\ttotal: 25.2s\tremaining: 3.67s\n",
      "873:\ttotal: 25.2s\tremaining: 3.64s\n",
      "874:\ttotal: 25.3s\tremaining: 3.61s\n",
      "875:\ttotal: 25.3s\tremaining: 3.58s\n",
      "876:\ttotal: 25.3s\tremaining: 3.55s\n",
      "877:\ttotal: 25.4s\tremaining: 3.52s\n",
      "878:\ttotal: 25.4s\tremaining: 3.49s\n",
      "879:\ttotal: 25.4s\tremaining: 3.46s\n",
      "880:\ttotal: 25.4s\tremaining: 3.44s\n",
      "881:\ttotal: 25.5s\tremaining: 3.41s\n",
      "882:\ttotal: 25.5s\tremaining: 3.38s\n",
      "883:\ttotal: 25.5s\tremaining: 3.35s\n",
      "884:\ttotal: 25.6s\tremaining: 3.32s\n",
      "885:\ttotal: 25.6s\tremaining: 3.29s\n",
      "886:\ttotal: 25.6s\tremaining: 3.26s\n",
      "887:\ttotal: 25.6s\tremaining: 3.23s\n",
      "888:\ttotal: 25.7s\tremaining: 3.2s\n",
      "889:\ttotal: 25.7s\tremaining: 3.17s\n",
      "890:\ttotal: 25.7s\tremaining: 3.15s\n",
      "891:\ttotal: 25.7s\tremaining: 3.12s\n",
      "892:\ttotal: 25.8s\tremaining: 3.09s\n",
      "893:\ttotal: 25.8s\tremaining: 3.06s\n",
      "894:\ttotal: 25.8s\tremaining: 3.03s\n",
      "895:\ttotal: 25.9s\tremaining: 3s\n",
      "896:\ttotal: 25.9s\tremaining: 2.97s\n",
      "897:\ttotal: 25.9s\tremaining: 2.94s\n",
      "898:\ttotal: 25.9s\tremaining: 2.92s\n",
      "899:\ttotal: 26s\tremaining: 2.89s\n",
      "900:\ttotal: 26s\tremaining: 2.86s\n",
      "901:\ttotal: 26s\tremaining: 2.83s\n",
      "902:\ttotal: 26.1s\tremaining: 2.8s\n",
      "903:\ttotal: 26.1s\tremaining: 2.77s\n",
      "904:\ttotal: 26.1s\tremaining: 2.74s\n",
      "905:\ttotal: 26.1s\tremaining: 2.71s\n",
      "906:\ttotal: 26.2s\tremaining: 2.68s\n",
      "907:\ttotal: 26.2s\tremaining: 2.65s\n",
      "908:\ttotal: 26.2s\tremaining: 2.63s\n",
      "909:\ttotal: 26.3s\tremaining: 2.6s\n",
      "910:\ttotal: 26.3s\tremaining: 2.57s\n",
      "911:\ttotal: 26.3s\tremaining: 2.54s\n",
      "912:\ttotal: 26.3s\tremaining: 2.51s\n",
      "913:\ttotal: 26.4s\tremaining: 2.48s\n",
      "914:\ttotal: 26.4s\tremaining: 2.45s\n",
      "915:\ttotal: 26.4s\tremaining: 2.42s\n",
      "916:\ttotal: 26.5s\tremaining: 2.4s\n",
      "917:\ttotal: 26.5s\tremaining: 2.37s\n",
      "918:\ttotal: 26.5s\tremaining: 2.34s\n",
      "919:\ttotal: 26.5s\tremaining: 2.31s\n",
      "920:\ttotal: 26.6s\tremaining: 2.28s\n",
      "921:\ttotal: 26.6s\tremaining: 2.25s\n",
      "922:\ttotal: 26.6s\tremaining: 2.22s\n",
      "923:\ttotal: 26.7s\tremaining: 2.19s\n",
      "924:\ttotal: 26.7s\tremaining: 2.16s\n",
      "925:\ttotal: 26.7s\tremaining: 2.13s\n",
      "926:\ttotal: 26.7s\tremaining: 2.11s\n",
      "927:\ttotal: 26.8s\tremaining: 2.08s\n",
      "928:\ttotal: 26.8s\tremaining: 2.05s\n",
      "929:\ttotal: 26.8s\tremaining: 2.02s\n",
      "930:\ttotal: 26.9s\tremaining: 1.99s\n",
      "931:\ttotal: 26.9s\tremaining: 1.96s\n",
      "932:\ttotal: 26.9s\tremaining: 1.93s\n",
      "933:\ttotal: 26.9s\tremaining: 1.9s\n",
      "934:\ttotal: 27s\tremaining: 1.88s\n",
      "935:\ttotal: 27s\tremaining: 1.85s\n",
      "936:\ttotal: 27s\tremaining: 1.82s\n",
      "937:\ttotal: 27.1s\tremaining: 1.79s\n",
      "938:\ttotal: 27.1s\tremaining: 1.76s\n",
      "939:\ttotal: 27.1s\tremaining: 1.73s\n",
      "940:\ttotal: 27.1s\tremaining: 1.7s\n",
      "941:\ttotal: 27.2s\tremaining: 1.67s\n",
      "942:\ttotal: 27.2s\tremaining: 1.64s\n",
      "943:\ttotal: 27.2s\tremaining: 1.61s\n",
      "944:\ttotal: 27.3s\tremaining: 1.59s\n",
      "945:\ttotal: 27.3s\tremaining: 1.56s\n",
      "946:\ttotal: 27.3s\tremaining: 1.53s\n",
      "947:\ttotal: 27.4s\tremaining: 1.5s\n",
      "948:\ttotal: 27.4s\tremaining: 1.47s\n",
      "949:\ttotal: 27.4s\tremaining: 1.44s\n",
      "950:\ttotal: 27.4s\tremaining: 1.41s\n",
      "951:\ttotal: 27.5s\tremaining: 1.38s\n",
      "952:\ttotal: 27.5s\tremaining: 1.36s\n",
      "953:\ttotal: 27.5s\tremaining: 1.33s\n",
      "954:\ttotal: 27.6s\tremaining: 1.3s\n",
      "955:\ttotal: 27.6s\tremaining: 1.27s\n",
      "956:\ttotal: 27.6s\tremaining: 1.24s\n",
      "957:\ttotal: 27.6s\tremaining: 1.21s\n",
      "958:\ttotal: 27.7s\tremaining: 1.18s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "959:\ttotal: 27.7s\tremaining: 1.15s\n",
      "960:\ttotal: 27.7s\tremaining: 1.13s\n",
      "961:\ttotal: 27.8s\tremaining: 1.1s\n",
      "962:\ttotal: 27.8s\tremaining: 1.07s\n",
      "963:\ttotal: 27.8s\tremaining: 1.04s\n",
      "964:\ttotal: 27.8s\tremaining: 1.01s\n",
      "965:\ttotal: 27.9s\tremaining: 981ms\n",
      "966:\ttotal: 27.9s\tremaining: 952ms\n",
      "967:\ttotal: 27.9s\tremaining: 924ms\n",
      "968:\ttotal: 28s\tremaining: 895ms\n",
      "969:\ttotal: 28s\tremaining: 866ms\n",
      "970:\ttotal: 28s\tremaining: 837ms\n",
      "971:\ttotal: 28.1s\tremaining: 808ms\n",
      "972:\ttotal: 28.1s\tremaining: 779ms\n",
      "973:\ttotal: 28.1s\tremaining: 750ms\n",
      "974:\ttotal: 28.1s\tremaining: 722ms\n",
      "975:\ttotal: 28.2s\tremaining: 693ms\n",
      "976:\ttotal: 28.2s\tremaining: 664ms\n",
      "977:\ttotal: 28.2s\tremaining: 635ms\n",
      "978:\ttotal: 28.3s\tremaining: 606ms\n",
      "979:\ttotal: 28.3s\tremaining: 577ms\n",
      "980:\ttotal: 28.3s\tremaining: 548ms\n",
      "981:\ttotal: 28.3s\tremaining: 519ms\n",
      "982:\ttotal: 28.4s\tremaining: 491ms\n",
      "983:\ttotal: 28.4s\tremaining: 462ms\n",
      "984:\ttotal: 28.4s\tremaining: 433ms\n",
      "985:\ttotal: 28.4s\tremaining: 404ms\n",
      "986:\ttotal: 28.5s\tremaining: 375ms\n",
      "987:\ttotal: 28.5s\tremaining: 346ms\n",
      "988:\ttotal: 28.5s\tremaining: 317ms\n",
      "989:\ttotal: 28.6s\tremaining: 289ms\n",
      "990:\ttotal: 28.6s\tremaining: 260ms\n",
      "991:\ttotal: 28.6s\tremaining: 231ms\n",
      "992:\ttotal: 28.6s\tremaining: 202ms\n",
      "993:\ttotal: 28.7s\tremaining: 173ms\n",
      "994:\ttotal: 28.7s\tremaining: 144ms\n",
      "995:\ttotal: 28.7s\tremaining: 115ms\n",
      "996:\ttotal: 28.8s\tremaining: 86.6ms\n",
      "997:\ttotal: 28.8s\tremaining: 57.7ms\n",
      "998:\ttotal: 28.8s\tremaining: 28.9ms\n",
      "999:\ttotal: 28.8s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostClassifier(\n",
    "    cat_features=['first_word', 'last_word'],\n",
    "    text_features=['line'],\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    task_type='CPU',\n",
    "    text_processing = {\n",
    "        \"tokenizers\" : [{\n",
    "            \"tokenizer_id\" : \"Space\",\n",
    "            \"separator_type\" : \"ByDelimiter\",\n",
    "            \"delimiter\" : \" \"\n",
    "        }],\n",
    "\n",
    "        \"dictionaries\" : [{\n",
    "            \"dictionary_id\" : \"BiGram\",\n",
    "            \"token_level_type\": \"Letter\",\n",
    "            \"max_dictionary_size\" : \"50000\",\n",
    "            \"occurrence_lower_bound\" : \"5\",\n",
    "            \"gram_order\" : \"2\"\n",
    "        },\n",
    "        {\n",
    "            \"dictionary_id\" : \"UniGram\",\n",
    "            \"token_level_type\": \"Letter\",\n",
    "            \"max_dictionary_size\" : \"50000\",\n",
    "            \"occurrence_lower_bound\" : \"5\",\n",
    "            \"gram_order\" : \"2\"\n",
    "        }\n",
    "        ],\n",
    "\n",
    "        \"feature_processing\" : {\n",
    "            \"default\" : [\n",
    "                    {\n",
    "                    \"dictionaries_names\" : [\"UniGram\", \"BiGram\"],\n",
    "                    \"feature_calcers\" : [\"BoW\"],\n",
    "                    \"tokenizers_names\" : [\"Space\"]\n",
    "                },\n",
    "                    {\n",
    "                \"dictionaries_names\" : [\"UniGram\", \"BiGram\"],\n",
    "                \"feature_calcers\" : [\"NaiveBayes\"],\n",
    "                \"tokenizers_names\" : [\"Space\"]\n",
    "            },{\n",
    "                \"dictionaries_names\" : [\"UniGram\", \"BiGram\"],\n",
    "                \"feature_calcers\" : [\"BM25\"],\n",
    "                \"tokenizers_names\" : [\"Space\"]\n",
    "            },\n",
    "            ],\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "cols = list(ed_texts_df)\n",
    "cols.pop(cols.index('label'))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(pd.DataFrame(ed_texts_df[cols]), \n",
    "                                                    ed_texts_df['label'], \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=ed_texts_df['label'])\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.82      3697\n",
      "           1       0.72      0.52      0.61      2066\n",
      "\n",
      "    accuracy                           0.76      5763\n",
      "   macro avg       0.75      0.71      0.72      5763\n",
      "weighted avg       0.75      0.76      0.75      5763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "f1_scores = []\n",
    "\n",
    "for treshold in tresholds:\n",
    "    y_probs = learner.predict_proba(x_test)\n",
    "    y_preds = np.where(y_probs[:, 1] > treshold, 1, 0)\n",
    "    accuracies.append((treshold, accuracy_score(y_preds, y_test)))\n",
    "    f1_scores.append((treshold, f1_score(y_preds, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1, 0.6475929054054054),\n",
       " (0.2, 0.692356418918919),\n",
       " (0.3, 0.7347972972972973),\n",
       " (0.4, 0.7655194256756757),\n",
       " (0.5, 0.7857896959459459),\n",
       " (0.6, 0.7849451013513513),\n",
       " (0.7, 0.7504222972972973),\n",
       " (0.8, 0.6731418918918919),\n",
       " (0.9, 0.5365287162162162)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1, 0.7710876422987245),\n",
       " (0.2, 0.7923614080091208),\n",
       " (0.3, 0.8130395951175944),\n",
       " (0.4, 0.825489117623949),\n",
       " (0.5, 0.8309870887130363),\n",
       " (0.6, 0.8164699522479503),\n",
       " (0.7, 0.7636),\n",
       " (0.8, 0.6429889298892989),\n",
       " (0.9, 0.3730362753499)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.64      0.71      3821\n",
      "           1       0.79      0.88      0.83      5651\n",
      "\n",
      "    accuracy                           0.79      9472\n",
      "   macro avg       0.79      0.76      0.77      9472\n",
      "weighted avg       0.79      0.79      0.78      9472\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_probs = learner.predict_proba(x_test)\n",
    "y_preds = np.where(y_probs[:, 1] > 0.5, 1, 0)\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2555,  560],\n",
       "       [1156, 2594]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7514484356894554"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "CatBoostClassifier.save_model(model, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_file = CatBoostClassifier()\n",
    "model = from_file.load_model(\"../models/catboost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f79caee7250>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9201/3600594002.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_preds' is not defined"
     ]
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
